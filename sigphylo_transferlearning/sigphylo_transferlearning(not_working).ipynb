{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toy model bayesian signature inference\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist \n",
    "from torch.distributions import constraints\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#define the model in terms of M = phylogenetic signature matrix, K_denovo = number of signatures we want to infer de novo,\n",
    "# K_fixed = number of signatures we already know. The fixed signatures are described by the fixed matrix Beta_fixed. \n",
    "# We provide an adjacency matrix A with binary entries which specify the correlation structure imposed by the phylogeny. \n",
    "# K = K_denovo + K_fixed\n",
    "# M has dims (num_branches,96)\n",
    "# theta is a vector encoding the number of mutations for each branch\n",
    "# beta prior and alpha prior provide densities for the dirichlet priors for Beta_denovo and alpha (activities matrix)\n",
    "# beta prior has dims (K_denovo,96), alpha prior has dims (num_branches,K_denovo)\n",
    "\n",
    "\n",
    "def model_single_run(M,beta_fixed,K_denovo,beta_prior,alpha_prior):\n",
    "    \n",
    "    num_samples = M.size()[0]\n",
    "    \n",
    "    K_fixed = beta_fixed.size()[0]\n",
    "    \n",
    "    theta = torch.sum(M,axis = 1)\n",
    "    \n",
    "    #parametrize the activity matrix as theta*alpha, where theta encodes the total number of mutations of the branches \n",
    "    # and alpha are percentages of signature activity\n",
    "    \n",
    "   # sample alpha from a dirichlet distribution using alpha prior\n",
    "\n",
    "    alpha = pyro.sample(\"activities\", dist.Dirichlet(alpha_prior))\n",
    "    \n",
    "    # sample the extra signature profiles from dirichlet distribution\n",
    "    \n",
    "    beta_denovo = pyro.sample(\"extra_signatures\", dist.Dirichlet(beta_prior))    \n",
    "        \n",
    "   # write the likelihood\n",
    "\n",
    "    with pyro.plate(\"context\",96):\n",
    "        \n",
    "        with pyro.plate(\"sample\",num_samples):\n",
    "    \n",
    "            pyro.sample(\"obs\", dist.Poisson(torch.matmul(torch.matmul(torch.diag(theta),alpha), \n",
    "                                            torch.cat((beta_fixed,beta_denovo),0))), obs = M)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.infer.autoguide.initialization import init_to_sample\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam  \n",
    "\n",
    "\n",
    "# perform MAP estimates with autodelta\n",
    "\n",
    "guide_single_run = AutoDelta(model_single_run, init_loc_fn = init_to_sample)  \n",
    "\n",
    "# SVI\n",
    "\n",
    "def inference_single_run(M,beta_fixed,K_denovo,beta_prior,alpha_prior,lr=0.05,num_steps = 200):\n",
    "\n",
    "    pyro.clear_param_store()  # always clear the store before the inference\n",
    "\n",
    "    # learning global parameters\n",
    "\n",
    "    adam_params = {\"lr\": lr}\n",
    "    optimizer = Adam(adam_params)\n",
    "    elbo = Trace_ELBO()\n",
    "\n",
    "    svi = SVI(model_single_run, guide_single_run, optimizer, loss=elbo)\n",
    "\n",
    "#   inference\n",
    "\n",
    "#   do gradient steps\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        loss = svi.step(M,beta_fixed,K_denovo,beta_prior,alpha_prior) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transfer_coeff(parameters,M,beta_fixed,A,hyper_lambda):\n",
    "    \n",
    "    beta_denovo = parameters[\"AutoDelta.extra_signatures\"]\n",
    "    \n",
    "    alpha = parameters[\"AutoDelta.activities\"]\n",
    "    \n",
    "    beta = torch.cat((beta_fixed,beta_denovo),0)\n",
    "    \n",
    "    theta = torch.sum(M,axis = 1)\n",
    "    \n",
    "    K = beta.size()[0]\n",
    "    \n",
    "    num_sumples = M.size()[0]\n",
    "    \n",
    "    cos = torch.zeros(num_samples,num_samples)\n",
    "    \n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        \n",
    "        for j in range(num_samples):\n",
    "        \n",
    "            if A[i,j] == 1:\n",
    "                \n",
    "                M_r = theta[i]*torch.matmul(alpha[j],beta)\n",
    "                \n",
    "                cos[i,j] = torch.dot(M[i],M_r)/(torch.norm(M[i])*torch.norm(M_r))\n",
    "                \n",
    "    \n",
    "    w = cos/torch.sum(cos,axis = 1)\n",
    "    \n",
    "    transfer_coeff = torch.zeros(num_samples,num_samples)\n",
    "    \n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        \n",
    "        for j in range(num_samples):\n",
    "            \n",
    "            if i==j:\n",
    "                \n",
    "                transfer_coeff[i,j]  = (1-hyper_lambda)*w[i,j]\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                transfer_coeff[i,j]  = hyper_lambda*w[i,j]\n",
    "     \n",
    "    \n",
    "    return transfer_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_inference(M,A,beta_fixed,K_denovo,hyper_lambda,lr = 0.05,steps_per_iteration = 200,num_iterations = 10):\n",
    "\n",
    "\n",
    "    # first indipendent run\n",
    "    \n",
    "    num_samples = M.size()[0]\n",
    "    \n",
    "    K_fixed = beta_fixed.size()[0]\n",
    "            \n",
    "    # step 0 : indipendent inference\n",
    "    \n",
    "    print(\"iteration \",0)\n",
    "            \n",
    "    alpha_prior = torch.ones(num_samples,K_denovo + K_fixed)/(K_denovo + K_fixed)\n",
    "            \n",
    "    beta_prior = torch.ones(K_denovo,96)/96\n",
    "\n",
    "    inference_single_run(M,beta_fixed,K_denovo,beta_prior,alpha_prior,lr = lr, \n",
    "                                            num_steps = steps_per_iteration)\n",
    "    \n",
    "    \n",
    "    # do iterations transferring alpha's\n",
    "            \n",
    "    for i in range(num_iterations):    \n",
    "                    \n",
    "            print(\"iteration \", i+1)\n",
    "            \n",
    "             \n",
    "            #extract inferred alpha's and beta'a from pyro store\n",
    "            \n",
    "            parameters={}\n",
    "        \n",
    "            for key in pyro.get_param_store().get_all_param_names() :\n",
    "    \n",
    "                parameters.update({key : torch.tensor(pyro.param(key))})\n",
    "        \n",
    "    \n",
    "            alpha_prior = parameters[\"AutoDelta.activities\"]\n",
    "        \n",
    "            beta_prior = parameters[\"AutoDelta.extra_signatures\"]\n",
    "            \n",
    "            \n",
    "            # calculate transfer coeff\n",
    "            \n",
    "            transfer_coeff = calculate_transfer_coeff(parameters,M,beta_fixed,A,hyper_lambda)\n",
    "            \n",
    "            \n",
    "            #update alpha prior with transfer coeff\n",
    "            \n",
    "            alpha_prior = torch.matmul(transfer_coeff,alpha_prior)\n",
    "            \n",
    "            \n",
    "            # do inference with updates alpha_prior and beta_prior\n",
    "    \n",
    "            inference_single_run(M, beta_fixed, K_denovo, beta_prior, alpha_prior, lr = lr, \n",
    "                                            num_steps = steps_per_iteration)\n",
    "    \n",
    "            print(\"activities distance = \" , torch.norm(parameters[\"AutoDelta.activities\"] - alpha_prior))\n",
    "            \n",
    "               \n",
    "    \n",
    "    \n",
    "    #save final inference\n",
    "    \n",
    "    alpha_denovo = parameters[\"AutoDelta.activities\"]\n",
    "        \n",
    "    beta_denovo = parameters[\"AutoDelta.extra_signatures\"]        \n",
    "        \n",
    "    SigPhylo = {\"alpha\" : alpha_denovo, \"beta\" : beta_denovo, \"lambda\" : hyper_lambda, \"K de novo\": K_denovo}\n",
    "                \n",
    "       \n",
    "    return SigPhylo\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "X_1 = pd.read_csv(\"Documents/GitHub/SigPhylo/toy_model/sample_1.csv\")\n",
    "X_2 = pd.read_csv(\"Documents/GitHub/SigPhylo/toy_model/sample_2.csv\")\n",
    "c_1 = X_1.values[:,1:]\n",
    "c_2 = X_2.values[:,1:]\n",
    "M_1 = torch.tensor(np.array(c_1,dtype=float))\n",
    "M_2 = torch.tensor(np.array(c_2,dtype=float))\n",
    "M_1 = M_1.float()\n",
    "M_2 = M_2.float()\n",
    "clock_like_signatures = pd.read_csv(\"Documents/GitHub/SigPhylo/toy_model/beta_aging.csv\")\n",
    "beta_fixed = clock_like_signatures.values[:,1:]\n",
    "beta_fixed = torch.tensor(np.array(beta_fixed,dtype=float))\n",
    "beta_fixed = beta_fixed.float()\n",
    "A = torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample 1\n",
    "\n",
    "full_inference(M_1,A,beta_fixed,K_denovo=2,hyper_lambda=0.1,lr = 0.05,steps_per_iteration = 200,num_iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
