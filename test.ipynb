{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenab/Library/r-miniconda-arm64/envs/basilica-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pybasilica.run as run\n",
    "import torch\n",
    "import pyro\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(x,y):\n",
    "    assert len(x) == len(y)\n",
    "    N = len(x)\n",
    "\n",
    "    # Obtain all possible classes\n",
    "    x_classes = list(np.unique(x))\n",
    "    y_classes = list(np.unique(y))\n",
    "    classes = set(x_classes + y_classes)\n",
    "\n",
    "    # Compute cardinality of every classes\n",
    "    px, py, pxy = {}, {}, {}\n",
    "    for c in classes:\n",
    "        px[c] = np.count_nonzero(x == c)\n",
    "        py[c] = np.count_nonzero(y == c)\n",
    "\n",
    "        pxy[c] = len(set(np.argwhere(x==c)[:,0]).intersection(set(np.argwhere(y==c)[:,0])))\n",
    "\n",
    "    print(px, py)\n",
    "\n",
    "    I = 0\n",
    "    for cx in x_classes:\n",
    "        for cy in y_classes:\n",
    "            pxy = len(set(np.argwhere(x==cx)[:,0]).intersection(set(np.argwhere(y==cy)[:,0])))\n",
    "            print(pxy)\n",
    "\n",
    "            if pxy > 0:\n",
    "                print(pxy / N)\n",
    "                print(np.log(N * pxy / (px[cx] * py[cy])))\n",
    "                print(N * pxy)\n",
    "                I += pxy / N * np.log(N * pxy / (px[cx] * py[cy]))\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0 for _ in range(10000)]\n",
    "b = [0 for _ in range(9999)] + [1 for _ in range(1)] \n",
    "sklearn.metrics.normalized_mutual_info_score(a, b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_path = \"test_simul_counts.csv\"\n",
    "m_g = pd.read_csv(m_path)\n",
    "m = m_g.drop([\"groups\", \"groups_rare\"], axis=1)\n",
    "g = m_g[\"groups\"].tolist()\n",
    "g_rare = m_g[\"groups_rare\"].tolist()\n",
    "ref_path = \"COSMIC_filt.csv\"\n",
    "cosmic = pd.read_csv(ref_path, index_col=0)\n",
    "k_list = [4,5]  # true is 4\n",
    "cluster = [4]  # true is 3 + 1 rare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(pyro.distributions.HalfNormal(0.5).sample((100,)).tolist(), bins=100, binrange=(0,15))\n",
    "sns.displot(pyro.distributions.HalfCauchy(0.5).sample((100,)).tolist(), bins=100, binrange=(0,15)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(pyro.distributions.Normal(0.3, 0.05).sample((100,)).tolist(), bins=100, binrange=(0,20)) \n",
    "# sns.displot(pyro.distributions.StudentT(0.3, 0.05).sample((100,)).tolist(), bins=100, binrange=(0,20)) \n",
    "# sns.displot(pyro.distributions.HalfCauchy(0.3, 0.05).sample((100,)).tolist(), bins=100, binrange=(0,20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model with 4 signatures, 4 groups and 92 seed\n",
      "\n",
      "N parameters 1312\n",
      "Running model with 5 signatures, 4 groups and 92 seed\n",
      "\n",
      "N parameters 1562\n"
     ]
    }
   ],
   "source": [
    "one = run.fit(\n",
    "    x=m, \n",
    "    k_list=k_list, \n",
    "    lr=0.005, \n",
    "    n_steps=10, \n",
    "    cluster=cluster, \n",
    "    beta_fixed=cosmic.loc[[\"SBS1\",\"SBS5\"]], \n",
    "    # hyperparameters={\"alpha_sigma\":.05, \"alpha_p_sigma\":1., \"alpha_p_conc0\":0.6, \"alpha_p_conc1\":0.6, \"alpha_rate\":1., \"pi_conc0\":0.5},\n",
    "    enforce_sparsity = True, \n",
    "    reg_weight = 0., \n",
    "    store_parameters=False, \n",
    "    verbose = False, \n",
    "    save_runs_seed=True,\n",
    "    seed=[92],\n",
    "    new_hier = False, \n",
    "    nonparametric = False,\n",
    "    save_all_fits=True\n",
    "    )\n",
    "\n",
    "obj = one[0] \n",
    "# 5 = n_samples, 1,2 + 2 = n_sigs, 2 = n_groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pybasilica.svi.PyBasilica at 0x157e33910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.all_fits[\"K_5.G_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj.inf_groups = obj.groups\n",
    "# obj.groups = obj.init_params[\"init_clusters\"].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 26, 1: 55, 2: 38, 3: 31}\n",
      "{1: 55, 2: 45, 3: 42, 4: 8}\n",
      "{1: 63, 2: 45, 3: 42}\n",
      "\n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "print({i:obj.groups.count(i) for i in set(obj.groups)})\n",
    "print({i:g_rare.count(i) for i in set(g_rare)})\n",
    "print({i:g.count(i) for i in set(g)} ) \n",
    "\n",
    "print(\"\\n\", obj.k_denovo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7105893115261042\n",
      "0.6619089758400103 \n",
      "\n",
      "0.7509727025956865\n",
      "0.7421423676094429\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.normalized_mutual_info_score(obj.groups, g_rare))\n",
    "print(sklearn.metrics.adjusted_rand_score(obj.groups, g_rare), \"\\n\")\n",
    "print(sklearn.metrics.normalized_mutual_info_score(obj.groups, g))\n",
    "print(sklearn.metrics.adjusted_rand_score(obj.groups, g)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5733, 0.1333, 0.1667, 0.1267], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.init_params[\"pi_param\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9911840040963293,\n",
       " 0.0021281413622185703,\n",
       " 0.003026402029660946,\n",
       " 0.00366145251179123]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1578, 0.6601, 0.7742])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.params[\"pi_conc0\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [i for i, v in enumerate(g_rare) if v == 4]\n",
    "print([v for i, v in enumerate(obj.groups) if i in idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(obj.losses)), y=obj.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj.gradient_norms[\"alpha_prior_param\"])), y=obj.gradient_norms[\"alpha_prior_param\"]) \n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj.gradient_norms[\"alpha_noise_param\"])), y=obj.gradient_norms[\"alpha_noise_param\"])\n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj.gradient_norms[\"alpha\"])), y=obj.gradient_norms[\"alpha\"]) \n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj.gradient_norms[\"beta_denovo\"])), y=obj.gradient_norms[\"beta_denovo\"])\n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj.gradient_norms[\"pi_param\"])), y=obj.gradient_norms[\"pi_param\"]) \n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(obj.init_params[\"alpha_prior_param\"]), columns=obj.alpha.columns).plot.bar(stacked=True, legend=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: pd.DataFrame(np.array(obj.alpha_prior), columns=obj.alpha.columns).plot.bar(stacked=True, legend=False) \n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: pd.DataFrame(np.array(obj.alpha_prior_unn), columns=obj.alpha.columns).plot.bar(stacked=True)\n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(obj.alpha_prior) \n",
    "# print(obj.init_params[\"alpha_t_param\"]) \n",
    "# print(pyro.param(\"alpha_prior_param\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for gid in set(obj.groups):\n",
    "        tmp = [i for i, v in enumerate(obj.groups) if v == gid]\n",
    "        pd.DataFrame(np.array(obj.alpha_noise), columns=obj.alpha.columns).iloc[tmp].plot.bar(stacked=True) \n",
    "    # pd.DataFrame(np.array(obj.alpha_noise), columns=obj.alpha.columns).iloc[idxs].plot.bar(stacked=True, legend=False)\n",
    "except:\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for gid in set(obj.groups):\n",
    "        tmp = [i for i, v in enumerate(obj.groups) if v == gid]\n",
    "        # tmp = [i for i, v in enumerate(obj.groups) if (v == gid and i in idxs)]\n",
    "        if len(tmp) == 0: continue\n",
    "        pd.DataFrame(np.array(obj.alpha), columns=obj.alpha.columns, index=obj.alpha.index).iloc[tmp].plot.bar(stacked=True)\n",
    "except:\n",
    "    obj.alpha.plot.bar(stacked=True, legend=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj.alpha_noise.min()) \n",
    "print(obj.alpha_noise.max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([-.3,.3,.3,.5])\n",
    "print(torch.min(a))\n",
    "print(a / torch.sum(a)) \n",
    "print(a - torch.min(a)) \n",
    "print( (a - torch.min(a)) / torch.sum(a - torch.min(a)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, .6, .6, .8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(obj.pi, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.post_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.k_denovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.k_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.alpha_prior_unn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.alpha_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.alpha_unn + obj.alpha_noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro import distributions as distr\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# sns.displot(distr.HalfNormal(obj.hyperparameters[\"alpha_var\"]).sample_n(1000).tolist())\n",
    "# sns.displot(distr.Exponential(obj.hyperparameters[\"exp_rate\"]).sample_n(1000).tolist()) \n",
    "vars = distr.Normal(0, 0.005).sample_n(50).tolist()\n",
    "centrs = [distr.Normal(0.5, np.abs(v_i)).sample().tolist() for v_i in vars]\n",
    "\n",
    "pl = sns.scatterplot(x=vars, y=centrs)\n",
    "pl.axhline(0.5-0.05)\n",
    "pl.axhline(0.5+0.05)\n",
    "\n",
    "# sns.displot(vars)\n",
    "# sns.displot(distr.Normal(0, 0.01).sample_n(1000).tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(distr.Normal(0, 0.005).sample_n(1000).tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = one.epsilon.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two = run.fit(\n",
    "    x=x2, \n",
    "    k_list=[1,2,3,4,5], \n",
    "    lr=0.05, \n",
    "    n_steps=500, \n",
    "    enumer=False, \n",
    "    cluster=None, \n",
    "    groups=None, \n",
    "    beta_fixed=None, \n",
    "    compile_model = False, \n",
    "    CUDA = False, \n",
    "    enforce_sparsity = False, \n",
    "    regularizer = \"cosine\", \n",
    "    reg_weight = 1, \n",
    "    reg_bic = False, \n",
    "    store_parameters=False, \n",
    "    verbose=False, \n",
    "    stage = \"two\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "m1 = torch.tensor(m.values).float()\n",
    "alpha1 = torch.tensor(one.alpha.values).float()\n",
    "a1 = torch.matmul(torch.diag(torch.sum(m1, axis=1)), alpha1)\n",
    "\n",
    "m2 = torch.tensor(x2.values).float()\n",
    "alpha2 = torch.tensor(two.alpha.values).float()\n",
    "a2 = torch.matmul(torch.diag(torch.sum(m2, axis=1)), alpha2)\n",
    "\n",
    "b1 = torch.sum(a1, 1).unsqueeze(-1)\n",
    "b2 = torch.sum(a2, 1).unsqueeze(-1)\n",
    "b3 = b1 + b2\n",
    "\n",
    "alpha1 = a1 / b3\n",
    "alpha2 = a2 / b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = list(one.alpha.index)\n",
    "fixed_names = list(one.alpha.columns)\n",
    "denovo_names = list(two.alpha.columns)\n",
    "alpha1 = pd.DataFrame(np.array(alpha1), index=sample_names, columns=fixed_names)\n",
    "alpha2 = pd.DataFrame(np.array(alpha2), index=sample_names, columns=denovo_names)\n",
    "alpha = pd.concat([alpha1, alpha2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.tensor(alpha.values).float(), 1).unsqueeze(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
