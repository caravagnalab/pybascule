{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenab/Library/r-miniconda-arm64/envs/basilica-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pybasilica.run as run\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from pyro.distributions import constraints\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_weights(beta):\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "def model(data):\n",
    "    with pyro.plate(\"beta_plate\", T-1):\n",
    "        beta = pyro.sample(\"beta\",  dist.Beta(1, alpha))\n",
    "\n",
    "    with pyro.plate(\"mu_plate\", T):\n",
    "        mu = pyro.sample(\"mu\",  dist.MultivariateNormal(torch.zeros(2), 5 * torch.eye(2)))\n",
    "\n",
    "    with pyro.plate(\"data\", N):\n",
    "        z = pyro.sample(\"z\",  dist.Categorical(mix_weights(beta)))\n",
    "        pyro.sample(\"obs\",  dist.MultivariateNormal(mu[z], torch.eye(2)), obs=data)\n",
    "\n",
    "def guide(data):\n",
    "    kappa = pyro.param('kappa', lambda: dist.Uniform(0, 2).sample([T-1]), constraint=constraints.positive)\n",
    "    tau = pyro.param('tau', lambda: dist.MultivariateNormal(torch.zeros(2), 3 * torch.eye(2)).sample([T]))\n",
    "    phi = pyro.param('phi', lambda: dist.Dirichlet(1/T * torch.ones(T)).sample([N]), constraint=constraints.simplex)\n",
    "\n",
    "    with pyro.plate(\"beta_plate\", T-1):\n",
    "        q_beta = pyro.sample(\"beta\",  dist.Beta(torch.ones(T-1), kappa))\n",
    "\n",
    "    with pyro.plate(\"mu_plate\", T):\n",
    "        q_mu = pyro.sample(\"mu\",  dist.MultivariateNormal(tau, torch.eye(2)))\n",
    "\n",
    "    with pyro.plate(\"data\", N):\n",
    "        z = pyro.sample(\"z\",  dist.Categorical(phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat((dist.MultivariateNormal(-8 * torch.ones(2), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(8 * torch.ones(2), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(torch.tensor([1.5, 2]), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(torch.tensor([-0.5, 1]), torch.eye(2)).sample([50])))\n",
    "\n",
    "N = data.shape[0]\n",
    "T = 6\n",
    "optim = pyro.optim.Adam({\"lr\": 0.05})\n",
    "svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO())\n",
    "losses = []\n",
    "\n",
    "def train(num_iterations):\n",
    "    pyro.clear_param_store()\n",
    "    for j in tqdm(range(num_iterations)):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "\n",
    "def truncate(alpha, centers, weights):\n",
    "    threshold = alpha**-1 / 100.\n",
    "    true_centers = centers[weights > threshold]\n",
    "    true_weights = weights[weights > threshold] / torch.sum(weights[weights > threshold])\n",
    "    return true_centers, true_weights\n",
    "\n",
    "alpha = 0.1\n",
    "train(1000)\n",
    "\n",
    "# We make a point-estimate of our model parameters using the posterior means of tau and phi for the centers and weights\n",
    "Bayes_Centers_01, Bayes_Weights_01 = truncate(alpha, pyro.param(\"tau\").detach(), \n",
    "                                              torch.mean(pyro.param(\"phi\").detach(), dim=0))\n",
    "\n",
    "alpha = 1.5\n",
    "train(1000)\n",
    "\n",
    "# We make a point-estimate of our model parameters using the posterior means of tau and phi for the centers and weights\n",
    "Bayes_Centers_15, Bayes_Weights_15 = truncate(alpha, pyro.param(\"tau\").detach(), \n",
    "                                              torch.mean(pyro.param(\"phi\").detach(), dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bayes_Weights_01)\n",
    "print(Bayes_Weights_15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_g = pd.read_csv(\"test_datasets/counts_sbs.N150.G3.csv\")\n",
    "m_sbs = m_g.drop([\"groups\"], axis=1)\n",
    "g_sbs = m_g[\"groups\"].tolist()\n",
    "cosmic_sbs = pd.read_csv(\"test_datasets/COSMIC_filt.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_g = pd.read_csv(\"test_datasets/counts_dbs.N150.G3.csv\")\n",
    "m_dbs = m_g.drop([\"groups\"], axis=1)\n",
    "g_dbs = m_g[\"groups\"].tolist()\n",
    "cosmic_dbs = pd.read_csv(\"test_datasets/COSMIC_dbs.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_sbs = torch.tensor(cosmic_sbs.loc[[\"SBS6\",\"SBS17b\"]].values, dtype=torch.float64)\n",
    "ref_sbs = torch.tensor(cosmic_sbs.loc[[\"SBS1\",\"SBS2\",\"SBS5\"]].values, dtype=torch.float64)\n",
    "# k_denovo = dn_sbs.shape[0]\n",
    "# k_fixed = ref_sbs.shape[0]\n",
    "clusters = 6\n",
    "\n",
    "def mix_weights(beta):\n",
    "    '''\n",
    "    Function used for the stick-breaking process.\n",
    "    '''\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "conc = torch.tensor([0.36432, 0.383313626, 0.257168233, 0.005969330, 0.017175399])\n",
    "\n",
    "pi_beta = torch.zeros(len(conc))\n",
    "for i in range(len(conc)):\n",
    "    pi_beta[i] = pyro.sample(\"beta\", pyro.distributions.Beta(1, conc[i])) \n",
    "\n",
    "pi = mix_weights(pi_beta)\n",
    "\n",
    "print(pi_beta)\n",
    "print(torch.round(pi * 100))\n",
    "\n",
    "with pyro.plate(\"beta_d_plate\", len(conc)):\n",
    "    pi_beta2 = pyro.sample(\"beta\", pyro.distributions.Beta(1, conc)) \n",
    "\n",
    "print(pi_beta2)\n",
    "pi2 = mix_weights(pi_beta2)\n",
    "print(torch.round(pi2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(dist.Gamma(torch.tensor(0.2, dtype=torch.float64), 0.1).sample((1000,)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.round(dist.Dirichlet(torch.tensor([0.3, 0.5, 0.3])*10).sample((10,)), decimals=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.tensor([1.,2.,3.]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bar desc:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO 353651.992181: 100%|██████████| 100/100 [00:00<00:00, 237.94it/s]\n",
      "ELBO 68277.632891: 100%|██████████| 100/100 [00:00<00:00, 334.87it/s]\n",
      "ELBO 61816.418329: 100%|██████████| 100/100 [00:00<00:00, 320.59it/s]\n",
      "ELBO 69596.978394: 100%|██████████| 100/100 [00:00<00:00, 303.90it/s]\n",
      "ELBO 72219.654185: 100%|██████████| 100/100 [00:00<00:00, 267.16it/s]\n"
     ]
    }
   ],
   "source": [
    "obj_sbs = run.fit(\n",
    "    x=m_sbs, \n",
    "    k_list=[3], \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=100, \n",
    "    cluster=[2,3,5,6],\n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_sbs.loc[[\"SBS1\",\"SBS5\"]], \n",
    "    store_parameters = True, \n",
    "    seed_list=[30],\n",
    "    nonparametric=False,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"pi_conc0\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.302, 0.698])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(obj_sbs.params[\"pi\"], decimals=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.347, 0.506, 0.031, 0.035, 0.045, 0.036])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(obj_sbs.init_params[\"pi_param\"], decimals=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(pyro.distributions.Gamma(0.5,0.1).sample((100,)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs = run.fit(\n",
    "    alpha=obj_sbs.params[\"alpha\"],\n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=100, \n",
    "    cluster=6,\n",
    "    # hyperparameters={\"penalty_scale\":2},\n",
    "    store_parameters = False, \n",
    "    seed_list=[30],\n",
    "    nonparametric=True,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.gradient_norms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=obj_sbs.regs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=obj_sbs.likelihoods) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=[obj_sbs.likelihoods[i]+obj_sbs.regs[i] for i in range(100)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=obj_sbs.losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.init_params[\"beta_weights\"])\n",
    "print(obj_sbs.params[\"beta_w\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.init_params[\"beta_weights\"])\n",
    "print(obj_sbs.params[\"beta_w\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"alpha_star\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = torch.tensor(obj_sbs.params[\"beta_d\"].values)\n",
    "sbs1 = torch.tensor(cosmic_sbs.loc[[\"SBS1\"]].values)\n",
    "for i in range(dn.shape[0]):\n",
    "    print(torch.nn.functional.cosine_similarity(sbs1, dn[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_orig = pyro.distributions.Dirichlet(torch.tensor([1., 5.])).sample((100,)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a_orig**3\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x=a[:,0].tolist(), y=a[:,1].tolist(), ax=ax)\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "# Define the parameters\n",
    "alpha = [1, 1, 1]  # Adjust alpha values as needed\n",
    "power = 2.0  # Adjust the power parameter\n",
    "\n",
    "# Sample from the standard Dirichlet distribution\n",
    "sample = np.random.dirichlet(alpha)\n",
    "\n",
    "# Apply the transformation\n",
    "sample_away_from_mode = sample ** (1 / power)\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sample_away_from_mode)\n",
    "print(\"Sampled:\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# Define the parameters of the Dirichlet distribution\n",
    "alpha = torch.tensor([1.0, 5.0, 1.0])  # Replace with your alpha values\n",
    "\n",
    "# Sample from the Dirichlet distribution\n",
    "sampled_value = pyro.sample(\"sampled_value\", dist.Dirichlet(alpha))\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sampled_value)\n",
    "\n",
    "# Find the mode of the Dirichlet distribution\n",
    "mode = torch.argmax(alpha)\n",
    "\n",
    "print(\"Mode\", mode)\n",
    "\n",
    "# Create a mask to zero out the mode value\n",
    "mask = torch.ones_like(sampled_value)\n",
    "mask[mode] = 0\n",
    "\n",
    "# Zero out the mode value\n",
    "sampled_value = sampled_value * mask\n",
    "\n",
    "# Renormalize to make it a valid probability distribution\n",
    "sampled_value = sampled_value / sampled_value.sum()\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sampled_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = a_orig**(3)\n",
    "fig2, ax2 = plt.subplots()\n",
    "fig3, ax3 = plt.subplots()\n",
    "sns.histplot(a[:,0].tolist(), ax=ax2)\n",
    "sns.histplot(a[:,1].tolist(), ax=ax3)\n",
    "ax2.set_xlim(0,1)\n",
    "ax3.set_xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(fixed, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = torch.tensor(obj_sbs.beta_fixed.values)\n",
    "beta_w = torch.tensor(obj_sbs.params[\"beta_w\"].values)\n",
    "denovo = torch.tensor(obj_sbs.params[\"beta_d\"].values)\n",
    "cum_weights = torch.ones((obj_sbs.k_denovo, obj_sbs.k_fixed))/obj_sbs.k_fixed\n",
    "\n",
    "fixed_cum = obj_sbs._get_unique_beta_stick_breaking(beta_fixed=fixed, beta_denovo=None, beta_weights=cum_weights)\n",
    "fixed_cum = obj_sbs._norm_and_clamp(fixed_cum)\n",
    "\n",
    "print(torch.sum((fixed_cum * (torch.abs(fixed_cum - denovo)))) * torch.tensor(obj_sbs.x.values).sum())\n",
    "print(torch.sum((fixed_cum * (torch.abs(fixed_cum - denovo)))) * obj_sbs.x.shape[0] * obj_sbs.x.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obj_sbs.train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Dirichlet(fixed_cum*1000).log_prob(denovo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.gradient_norms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (1 - torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.n_samples * self.contexts * pyro.distributions.Dirichlet(beta_fixed_cum*1000).to_event(1).log_prob(beta_denovo))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.param(\"beta_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.gradient_norms.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"alpha\"].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_dn = 2\n",
    "k_f = 3\n",
    "n_samples = 5\n",
    "beta_weights = pyro.distributions.Dirichlet(torch.ones(k_dn, k_f+1)).sample()\n",
    "alpha_star = pyro.distributions.Dirichlet(torch.ones(n_samples, k_dn)).sample()\n",
    "print(\"beta weights\\n\", beta_weights)\n",
    "print(\"alpha star\\n\", alpha_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_weights[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.zeros((n_samples, k_dn+k_f))\n",
    "\n",
    "for n in range(n_samples):\n",
    "    for j in range(k_dn):\n",
    "        for r in range(k_f):\n",
    "            alpha[n, r] += torch.sum(alpha_star[n,j]) * beta_weights[j,r]\n",
    "        \n",
    "        for d in range(k_f, k_f+k_dn):\n",
    "            alpha[n, d] += torch.sum(alpha_star[n,j]) * beta_weights[j,-1]\n",
    "\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dbs = run.fit(\n",
    "    x=m_dbs, \n",
    "    k_list=3, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=10, \n",
    "    # cluster=6, \n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_dbs.loc[[\"DBS4\"]], \n",
    "    hyperparameters={\"alpha_sigma\":.15, \"alpha_p_sigma\":1., \"alpha_p_conc0\":0.6, \n",
    "                     \"alpha_p_conc1\":0.6, \"alpha_rate\":1., \"pi_conc0\":0.5, \"alpha_conc\":100,\n",
    "                     \"scale_factor_alpha\":10000, \"scale_factor_centroid\":1000, \"scale_tau\":0},\n",
    "    enforce_sparsity = True, \n",
    "    reg_weight=0., \n",
    "    store_parameters = True, \n",
    "    seed_list=[92],\n",
    "    nonparametric=True,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sbs = obj_sbs.params[\"alpha\"] \n",
    "alpha_dbs = obj_dbs.params[\"alpha\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [alpha_sbs, alpha_dbs] \n",
    "input_tensor = [torch.tensor(alpha_sbs.values), torch.tensor(alpha_dbs.values)]\n",
    "max_shape = max([i.shape[1] for i in input_tensor])\n",
    "# stacked = torch.stack(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = run.fit(\n",
    "    alpha=input, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=3000,\n",
    "    cluster=5, \n",
    "    hyperparameters={\"alpha_sigma\":.15, \"alpha_p_sigma\":1., \"alpha_p_conc0\":0.6, \n",
    "                     \"alpha_p_conc1\":0.6, \"alpha_rate\":1., \"pi_conc0\":0.5, \"alpha_conc\":100,\n",
    "                     \"scale_factor_alpha\":10000, \"scale_factor_centroid\":1000, \"scale_tau\":0},\n",
    "    store_parameters = True, \n",
    "    seed_list=[92],\n",
    "    nonparametric=True,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def mix_weights(beta):\n",
    "    '''\n",
    "    Function used for the stick-breaking process.\n",
    "    '''\n",
    "    print(\"beta =\", beta)\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    print(\"beta1m_cumprod =\", beta1m_cumprod)\n",
    "    res1 = F.pad(beta, (0, 1), value=1)\n",
    "    res2 = F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "    res = res1 * res2\n",
    "    print(f\"res1 = {res1}, res2 = {res2}, res = {res}\\n\")\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 6\n",
    "with pyro.plate(\"beta_plate\", cluster-1):\n",
    "    pi_beta = pyro.sample(f\"beta\", pyro.distributions.Beta(1, 1.1755e-36))\n",
    "    # pi_beta = torch.tensor([1.1755e-36, 2.1648e-18, 1.1755e-36, 6.6389e-33, 1.1755e-36])\n",
    "    print(\"pi_beta =\", pi_beta)\n",
    "    pi = mix_weights(pi_beta)\n",
    "\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_star = torch.zeros(k_denovo, 96, dtype=torch.float64) \n",
    "for i in range(k_denovo):\n",
    "    tmp_sbs = torch.cat((ref_sbs, dn_sbs[i].unsqueeze(0)))\n",
    "    beta_star[i] = pi[i].unsqueeze(0).matmul(tmp_sbs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Gamma(0.01, 0.01).sample((5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Dirichlet(torch.ones(5)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - pyro.distributions.Beta(1, 1e-10).sample((cluster-1,))).cumprod(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = torch.zeros((10,))\n",
    "pi[:5] = 5\n",
    "pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_centr = mixture[0].params[\"alpha_prior\"]\n",
    "print(alpha_centr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.normalized_mutual_info_score(mixture.groups, g_sbs)) \n",
    "print(sklearn.metrics.normalized_mutual_info_score(mixture.groups, g_dbs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"scale_factor_centroid\"])\n",
    "print(obj_sbs.params[\"scale_factor_alpha\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.train_params[6][\"scale_factor_centroid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"pi_conc0\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(obj_sbs.likelihoods)), y=obj_sbs.likelihoods) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(obj_sbs.losses)), y=obj_sbs.losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"scale_factor_centroid_param\"])), \n",
    "                     y=obj_sbs.gradient_norms[\"scale_factor_centroid_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"scale_factor_alpha_param\"])), \n",
    "                     y=obj_sbs.gradient_norms[\"scale_factor_alpha_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha_prior_param\"])), y=obj_sbs.gradient_norms[\"alpha_prior_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha_prior_param\"])), y=obj_sbs.gradient_norms[\"alpha_prior_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"pi_param\"])), y=obj_sbs.gradient_norms[\"pi_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"pi_conc0_param\"])), y=obj_sbs.gradient_norms[\"pi_conc0_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha\"])), y=obj_sbs.gradient_norms[\"alpha\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"beta_denovo\"])), y=obj_sbs.gradient_norms[\"beta_denovo\"])\n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(obj_sbs.init_params[\"alpha_prior_param\"]), columns=obj_sbs.params[\"alpha\"].columns).plot.bar(stacked=True, legend=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: pd.DataFrame(np.array(obj_sbs.params[\"alpha_prior\"]), columns=obj_sbs.params[\"alpha_prior\"].columns).plot.bar(stacked=True, legend=False) \n",
    "except Exception as e: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for gid in set(np.array(obj_sbs.groups)):\n",
    "        tmp = [i for i, v in enumerate(obj_sbs.groups) if v == gid]\n",
    "        # tmp = [i for i, v in enumerate(obj_sbs.groups) if (v == gid and i in idxs)]\n",
    "        if len(tmp) == 0: continue\n",
    "        pd.DataFrame(np.array(obj_sbs.params[\"alpha\"]), columns=obj_sbs.params[\"alpha\"].columns, \n",
    "                     index=obj_sbs.params[\"alpha\"].index).iloc[tmp].plot.bar(stacked=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    obj_sbs.alpha.plot.bar(stacked=True, legend=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for sbs in pd.concat((obj_sbs.params[\"beta_f\"], obj_sbs.params[\"beta_d\"])).index:\n",
    "        pd.concat((obj_sbs.params[\"beta_f\"], obj_sbs.params[\"beta_d\"])).loc[[sbs]].transpose().plot.bar()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
