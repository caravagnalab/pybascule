{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenab/Library/r-miniconda-arm64/envs/basilica-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pybasilica.run as run\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from pyro.distributions import constraints\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_weights(beta):\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "def model(data):\n",
    "    with pyro.plate(\"beta_plate\", T-1):\n",
    "        beta = pyro.sample(\"beta\",  dist.Beta(1, alpha))\n",
    "\n",
    "    with pyro.plate(\"mu_plate\", T):\n",
    "        mu = pyro.sample(\"mu\",  dist.MultivariateNormal(torch.zeros(2), 5 * torch.eye(2)))\n",
    "\n",
    "    with pyro.plate(\"data\", N):\n",
    "        z = pyro.sample(\"z\",  dist.Categorical(mix_weights(beta)))\n",
    "        pyro.sample(\"obs\",  dist.MultivariateNormal(mu[z], torch.eye(2)), obs=data)\n",
    "\n",
    "def guide(data):\n",
    "    kappa = pyro.param('kappa', lambda: dist.Uniform(0, 2).sample([T-1]), constraint=constraints.positive)\n",
    "    tau = pyro.param('tau', lambda: dist.MultivariateNormal(torch.zeros(2), 3 * torch.eye(2)).sample([T]))\n",
    "    phi = pyro.param('phi', lambda: dist.Dirichlet(1/T * torch.ones(T)).sample([N]), constraint=constraints.simplex)\n",
    "\n",
    "    with pyro.plate(\"beta_plate\", T-1):\n",
    "        q_beta = pyro.sample(\"beta\",  dist.Beta(torch.ones(T-1), kappa))\n",
    "\n",
    "    with pyro.plate(\"mu_plate\", T):\n",
    "        q_mu = pyro.sample(\"mu\",  dist.MultivariateNormal(tau, torch.eye(2)))\n",
    "\n",
    "    with pyro.plate(\"data\", N):\n",
    "        z = pyro.sample(\"z\",  dist.Categorical(phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat((dist.MultivariateNormal(-8 * torch.ones(2), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(8 * torch.ones(2), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(torch.tensor([1.5, 2]), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(torch.tensor([-0.5, 1]), torch.eye(2)).sample([50])))\n",
    "\n",
    "N = data.shape[0]\n",
    "T = 6\n",
    "optim = pyro.optim.Adam({\"lr\": 0.05})\n",
    "svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO())\n",
    "losses = []\n",
    "\n",
    "def train(num_iterations):\n",
    "    pyro.clear_param_store()\n",
    "    for j in tqdm(range(num_iterations)):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "\n",
    "def truncate(alpha, centers, weights):\n",
    "    threshold = alpha**-1 / 100.\n",
    "    true_centers = centers[weights > threshold]\n",
    "    true_weights = weights[weights > threshold] / torch.sum(weights[weights > threshold])\n",
    "    return true_centers, true_weights\n",
    "\n",
    "alpha = 0.1\n",
    "train(1000)\n",
    "\n",
    "# We make a point-estimate of our model parameters using the posterior means of tau and phi for the centers and weights\n",
    "Bayes_Centers_01, Bayes_Weights_01 = truncate(alpha, pyro.param(\"tau\").detach(), \n",
    "                                              torch.mean(pyro.param(\"phi\").detach(), dim=0))\n",
    "\n",
    "alpha = 1.5\n",
    "train(1000)\n",
    "\n",
    "# We make a point-estimate of our model parameters using the posterior means of tau and phi for the centers and weights\n",
    "Bayes_Centers_15, Bayes_Weights_15 = truncate(alpha, pyro.param(\"tau\").detach(), \n",
    "                                              torch.mean(pyro.param(\"phi\").detach(), dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bayes_Weights_01)\n",
    "print(Bayes_Weights_15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_g = pd.read_csv(\"test_datasets/counts_sbs.N150.G3.csv\")\n",
    "m_sbs = m_g.drop([\"groups\"], axis=1)\n",
    "g_sbs = m_g[\"groups\"].tolist()\n",
    "cosmic_sbs = pd.read_csv(\"test_datasets/COSMIC_filt.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_g = pd.read_csv(\"test_datasets/counts_dbs.N150.G3.csv\")\n",
    "m_dbs = m_g.drop([\"groups\"], axis=1)\n",
    "g_dbs = m_g[\"groups\"].tolist()\n",
    "cosmic_dbs = pd.read_csv(\"test_datasets/COSMIC_dbs.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn_sbs = torch.tensor(cosmic_sbs.loc[[\"SBS6\",\"SBS17b\"]].values, dtype=torch.float64)\n",
    "ref_sbs = torch.tensor(cosmic_sbs.loc[[\"SBS1\",\"SBS2\",\"SBS5\"]].values, dtype=torch.float64)\n",
    "# k_denovo = dn_sbs.shape[0]\n",
    "# k_fixed = ref_sbs.shape[0]\n",
    "clusters = 6\n",
    "\n",
    "def mix_weights(beta):\n",
    "    '''\n",
    "    Function used for the stick-breaking process.\n",
    "    '''\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "conc = torch.tensor([0.36432, 0.383313626, 0.257168233, 0.005969330, 0.017175399])\n",
    "\n",
    "pi_beta = torch.zeros(len(conc))\n",
    "for i in range(len(conc)):\n",
    "    pi_beta[i] = pyro.sample(\"beta\", pyro.distributions.Beta(1, conc[i])) \n",
    "\n",
    "pi = mix_weights(pi_beta)\n",
    "\n",
    "print(pi_beta)\n",
    "print(torch.round(pi * 100))\n",
    "\n",
    "with pyro.plate(\"beta_d_plate\", len(conc)):\n",
    "    pi_beta2 = pyro.sample(\"beta\", pyro.distributions.Beta(1, conc)) \n",
    "\n",
    "print(pi_beta2)\n",
    "pi2 = mix_weights(pi_beta2)\n",
    "print(torch.round(pi2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(dist.Gamma(torch.tensor(0.2, dtype=torch.float64), 0.1).sample((1000,)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.round(dist.Dirichlet(torch.tensor([0.3, 0.5, 0.3])*10).sample((10,)), decimals=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.tensor([1.,2.,3.]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO 412672.835312: 100%|██████████| 30/30 [00:00<00:00, 133.05it/s]\n",
      "ELBO 401137.627260: 100%|██████████| 30/30 [00:00<00:00, 270.06it/s]\n"
     ]
    }
   ],
   "source": [
    "obj_sbs = run.fit(\n",
    "    x=m_sbs, \n",
    "    k_list=[3,4], \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=30, \n",
    "    # cluster=[3],\n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_sbs.loc[[\"SBS1\",\"SBS5\"]], \n",
    "    store_parameters = True, \n",
    "    seed_list=[30],\n",
    "    nonparametric=False,\n",
    "    store_fits=True, enumer=\"parallel\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A[C&gt;A]A</th>\n",
       "      <th>A[C&gt;A]C</th>\n",
       "      <th>A[C&gt;A]G</th>\n",
       "      <th>A[C&gt;A]T</th>\n",
       "      <th>A[C&gt;G]A</th>\n",
       "      <th>A[C&gt;G]C</th>\n",
       "      <th>A[C&gt;G]G</th>\n",
       "      <th>A[C&gt;G]T</th>\n",
       "      <th>A[C&gt;T]A</th>\n",
       "      <th>A[C&gt;T]C</th>\n",
       "      <th>...</th>\n",
       "      <th>T[T&gt;A]G</th>\n",
       "      <th>T[T&gt;A]T</th>\n",
       "      <th>T[T&gt;C]A</th>\n",
       "      <th>T[T&gt;C]C</th>\n",
       "      <th>T[T&gt;C]G</th>\n",
       "      <th>T[T&gt;C]T</th>\n",
       "      <th>T[T&gt;G]A</th>\n",
       "      <th>T[T&gt;G]C</th>\n",
       "      <th>T[T&gt;G]G</th>\n",
       "      <th>T[T&gt;G]T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>0.011579</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.008795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.012739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.008675</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.012767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>0.014999</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.012020</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>0.010522</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.010109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A[C>A]A   A[C>A]C   A[C>A]G   A[C>A]T   A[C>G]A   A[C>G]C   A[C>G]G  \\\n",
       "D1  0.011579  0.010095  0.012632  0.009835  0.011338  0.009422  0.012560   \n",
       "D2  0.011893  0.009589  0.008940  0.010963  0.009675  0.011643  0.013388   \n",
       "D3  0.014999  0.012502  0.008392  0.012020  0.011432  0.008657  0.011146   \n",
       "\n",
       "     A[C>G]T   A[C>T]A   A[C>T]C  ...   T[T>A]G   T[T>A]T   T[T>C]A   T[T>C]C  \\\n",
       "D1  0.010064  0.010077  0.008795  ...  0.010186  0.010066  0.010769  0.010145   \n",
       "D2  0.009602  0.008675  0.010355  ...  0.009563  0.010390  0.008504  0.012030   \n",
       "D3  0.010522  0.007693  0.010635  ...  0.011806  0.009625  0.008624  0.007509   \n",
       "\n",
       "     T[T>C]G   T[T>C]T   T[T>G]A   T[T>G]C   T[T>G]G   T[T>G]T  \n",
       "D1  0.008506  0.011635  0.008568  0.008647  0.009724  0.012739  \n",
       "D2  0.012324  0.012108  0.011539  0.008215  0.010432  0.012767  \n",
       "D3  0.009552  0.011164  0.009902  0.007454  0.011682  0.010109  \n",
       "\n",
       "[3 rows x 96 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_sbs.fits[\"k_denovo:3\"][\"seed:30\"].params[\"beta_d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO 26539.833804: 100%|██████████| 3000/3000 [00:09<00:00, 311.81it/s]\n"
     ]
    }
   ],
   "source": [
    "obj_dbs = run.fit(\n",
    "    x=m_dbs, \n",
    "    k_list=3, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=3000, \n",
    "    # cluster=[3],\n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_dbs.loc[[\"DBS3\",\"DBS5\"]], \n",
    "    store_parameters = True, \n",
    "    seed_list=[30],\n",
    "    nonparametric=False,\n",
    "    store_fits=True, enumer=\"parallel\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_prior = dist.Dirichlet(torch.ones())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenab/Library/r-miniconda-arm64/envs/basilica-env/lib/python3.9/site-packages/pyro/infer/traceenum_elbo.py:355: UserWarning: TraceEnum_ELBO found no sample sites configured for enumeration. If you want to enumerate sites, you need to @config_enumerate or set infer={\"enumerate\": \"sequential\"} or infer={\"enumerate\": \"parallel\"}? If you do not want to enumerate, consider using Trace_ELBO instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pi_param': tensor([0.1731, 0.4812, 0.3457], dtype=torch.float64), 'alpha_prior_param': tensor([[[0.1146, 0.1476, 0.3894, 0.1951, 0.0943, 0.0591],\n",
      "         [0.2241, 0.0437, 0.4525, 0.1143, 0.1392, 0.0262]],\n",
      "\n",
      "        [[0.2146, 0.0470, 0.1093, 0.0583, 0.3878, 0.1831],\n",
      "         [0.0041, 0.1152, 0.2183, 0.4046, 0.1028, 0.1549]],\n",
      "\n",
      "        [[0.3165, 0.5735, 0.0499, 0.0313, 0.0204, 0.0083],\n",
      "         [0.0837, 0.0900, 0.1661, 0.1391, 0.2701, 0.2509]]],\n",
      "       dtype=torch.float64)}\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "{'pi_param': tensor([0.1731, 0.4812, 0.3457], dtype=torch.float64), 'alpha_prior_param': tensor([[[0.1146, 0.1476, 0.3894, 0.1951, 0.0943, 0.0591],\n",
      "         [0.2241, 0.0437, 0.4525, 0.1143, 0.1392, 0.0262]],\n",
      "\n",
      "        [[0.2146, 0.0470, 0.1093, 0.0583, 0.3878, 0.1831],\n",
      "         [0.0041, 0.1152, 0.2183, 0.4046, 0.1028, 0.1549]],\n",
      "\n",
      "        [[0.3165, 0.5735, 0.0499, 0.0313, 0.0204, 0.0083],\n",
      "         [0.0837, 0.0900, 0.1661, 0.1391, 0.2701, 0.2509]]],\n",
      "       dtype=torch.float64)}\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO 992368738.581902: 100%|██████████| 3/3 [00:00<00:00, 231.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pi_param': tensor([0.1731, 0.4812, 0.3457], dtype=torch.float64), 'alpha_prior_param': tensor([[[0.1146, 0.1476, 0.3894, 0.1951, 0.0943, 0.0591],\n",
      "         [0.2241, 0.0437, 0.4525, 0.1143, 0.1392, 0.0262]],\n",
      "\n",
      "        [[0.2146, 0.0470, 0.1093, 0.0583, 0.3878, 0.1831],\n",
      "         [0.0041, 0.1152, 0.2183, 0.4046, 0.1028, 0.1549]],\n",
      "\n",
      "        [[0.3165, 0.5735, 0.0499, 0.0313, 0.0204, 0.0083],\n",
      "         [0.0837, 0.0900, 0.1661, 0.1391, 0.2701, 0.2509]]],\n",
      "       dtype=torch.float64)}\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "{'pi_param': tensor([0.1731, 0.4812, 0.3457], dtype=torch.float64), 'alpha_prior_param': tensor([[[0.1146, 0.1476, 0.3894, 0.1951, 0.0943, 0.0591],\n",
      "         [0.2241, 0.0437, 0.4525, 0.1143, 0.1392, 0.0262]],\n",
      "\n",
      "        [[0.2146, 0.0470, 0.1093, 0.0583, 0.3878, 0.1831],\n",
      "         [0.0041, 0.1152, 0.2183, 0.4046, 0.1028, 0.1549]],\n",
      "\n",
      "        [[0.3165, 0.5735, 0.0499, 0.0313, 0.0204, 0.0083],\n",
      "         [0.0837, 0.0900, 0.1661, 0.1391, 0.2701, 0.2509]]],\n",
      "       dtype=torch.float64)}\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "{'pi_param': tensor([0.1731, 0.4812, 0.3457], dtype=torch.float64), 'alpha_prior_param': tensor([[[0.1146, 0.1476, 0.3894, 0.1951, 0.0943, 0.0591],\n",
      "         [0.2241, 0.0437, 0.4525, 0.1143, 0.1392, 0.0262]],\n",
      "\n",
      "        [[0.2146, 0.0470, 0.1093, 0.0583, 0.3878, 0.1831],\n",
      "         [0.0041, 0.1152, 0.2183, 0.4046, 0.1028, 0.1549]],\n",
      "\n",
      "        [[0.3165, 0.5735, 0.0499, 0.0313, 0.0204, 0.0083],\n",
      "         [0.0837, 0.0900, 0.1661, 0.1391, 0.2701, 0.2509]]],\n",
      "       dtype=torch.float64)}\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n",
      "torch.Size([150, 2, 6])\n",
      "torch.Size([3, 2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_alpha = [obj_sbs.params[\"alpha\"], obj_dbs.params[\"alpha\"]]\n",
    "obj_clust = run.fit(\n",
    "    alpha=input_alpha,\n",
    "    lr=0.005, \n",
    "    # optim_gamma=0.1,\n",
    "    n_steps=3, \n",
    "    cluster=[2,3],\n",
    "    store_parameters = False, \n",
    "    seed_list=[30],\n",
    "    nonparametric=False,\n",
    "    store_fits=True, enumer=\"parallel\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_SBS1</th>\n",
       "      <th>0_SBS5</th>\n",
       "      <th>0_D1</th>\n",
       "      <th>0_D2</th>\n",
       "      <th>0_D3</th>\n",
       "      <th>0_D4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131846</td>\n",
       "      <td>0.197937</td>\n",
       "      <td>0.264096</td>\n",
       "      <td>0.168362</td>\n",
       "      <td>0.155327</td>\n",
       "      <td>0.082433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209907</td>\n",
       "      <td>0.123766</td>\n",
       "      <td>0.243133</td>\n",
       "      <td>0.168334</td>\n",
       "      <td>0.156505</td>\n",
       "      <td>0.098354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222990</td>\n",
       "      <td>0.096834</td>\n",
       "      <td>0.165362</td>\n",
       "      <td>0.154621</td>\n",
       "      <td>0.191821</td>\n",
       "      <td>0.168372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0_SBS1    0_SBS5      0_D1      0_D2      0_D3      0_D4\n",
       "0  0.131846  0.197937  0.264096  0.168362  0.155327  0.082433\n",
       "1  0.209907  0.123766  0.243133  0.168334  0.156505  0.098354\n",
       "2  0.222990  0.096834  0.165362  0.154621  0.191821  0.168372"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_clust.params[\"alpha_prior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=obj_sbs.regs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=obj_sbs.likelihoods) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=[obj_sbs.likelihoods[i]+obj_sbs.regs[i] for i in range(100)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=[_ for _ in range(100)], y=obj_sbs.losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.init_params[\"beta_weights\"])\n",
    "print(obj_sbs.params[\"beta_w\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.init_params[\"beta_weights\"])\n",
    "print(obj_sbs.params[\"beta_w\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"alpha_star\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = torch.tensor(obj_sbs.params[\"beta_d\"].values)\n",
    "sbs1 = torch.tensor(cosmic_sbs.loc[[\"SBS1\"]].values)\n",
    "for i in range(dn.shape[0]):\n",
    "    print(torch.nn.functional.cosine_similarity(sbs1, dn[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_orig = pyro.distributions.Dirichlet(torch.tensor([1., 5.])).sample((100,)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a_orig**3\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x=a[:,0].tolist(), y=a[:,1].tolist(), ax=ax)\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "# Define the parameters\n",
    "alpha = [1, 1, 1]  # Adjust alpha values as needed\n",
    "power = 2.0  # Adjust the power parameter\n",
    "\n",
    "# Sample from the standard Dirichlet distribution\n",
    "sample = np.random.dirichlet(alpha)\n",
    "\n",
    "# Apply the transformation\n",
    "sample_away_from_mode = sample ** (1 / power)\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sample_away_from_mode)\n",
    "print(\"Sampled:\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# Define the parameters of the Dirichlet distribution\n",
    "alpha = torch.tensor([1.0, 5.0, 1.0])  # Replace with your alpha values\n",
    "\n",
    "# Sample from the Dirichlet distribution\n",
    "sampled_value = pyro.sample(\"sampled_value\", dist.Dirichlet(alpha))\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sampled_value)\n",
    "\n",
    "# Find the mode of the Dirichlet distribution\n",
    "mode = torch.argmax(alpha)\n",
    "\n",
    "print(\"Mode\", mode)\n",
    "\n",
    "# Create a mask to zero out the mode value\n",
    "mask = torch.ones_like(sampled_value)\n",
    "mask[mode] = 0\n",
    "\n",
    "# Zero out the mode value\n",
    "sampled_value = sampled_value * mask\n",
    "\n",
    "# Renormalize to make it a valid probability distribution\n",
    "sampled_value = sampled_value / sampled_value.sum()\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sampled_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = a_orig**(3)\n",
    "fig2, ax2 = plt.subplots()\n",
    "fig3, ax3 = plt.subplots()\n",
    "sns.histplot(a[:,0].tolist(), ax=ax2)\n",
    "sns.histplot(a[:,1].tolist(), ax=ax3)\n",
    "ax2.set_xlim(0,1)\n",
    "ax3.set_xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(fixed, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = torch.tensor(obj_sbs.beta_fixed.values)\n",
    "beta_w = torch.tensor(obj_sbs.params[\"beta_w\"].values)\n",
    "denovo = torch.tensor(obj_sbs.params[\"beta_d\"].values)\n",
    "cum_weights = torch.ones((obj_sbs.k_denovo, obj_sbs.k_fixed))/obj_sbs.k_fixed\n",
    "\n",
    "fixed_cum = obj_sbs._get_unique_beta_stick_breaking(beta_fixed=fixed, beta_denovo=None, beta_weights=cum_weights)\n",
    "fixed_cum = obj_sbs._norm_and_clamp(fixed_cum)\n",
    "\n",
    "print(torch.sum((fixed_cum * (torch.abs(fixed_cum - denovo)))) * torch.tensor(obj_sbs.x.values).sum())\n",
    "print(torch.sum((fixed_cum * (torch.abs(fixed_cum - denovo)))) * obj_sbs.x.shape[0] * obj_sbs.x.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obj_sbs.train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Dirichlet(fixed_cum*1000).log_prob(denovo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.gradient_norms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (1 - torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.n_samples * self.contexts * pyro.distributions.Dirichlet(beta_fixed_cum*1000).to_event(1).log_prob(beta_denovo))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.param(\"beta_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.gradient_norms.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"alpha\"].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_dn = 2\n",
    "k_f = 3\n",
    "n_samples = 5\n",
    "beta_weights = pyro.distributions.Dirichlet(torch.ones(k_dn, k_f+1)).sample()\n",
    "alpha_star = pyro.distributions.Dirichlet(torch.ones(n_samples, k_dn)).sample()\n",
    "print(\"beta weights\\n\", beta_weights)\n",
    "print(\"alpha star\\n\", alpha_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_weights[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.zeros((n_samples, k_dn+k_f))\n",
    "\n",
    "for n in range(n_samples):\n",
    "    for j in range(k_dn):\n",
    "        for r in range(k_f):\n",
    "            alpha[n, r] += torch.sum(alpha_star[n,j]) * beta_weights[j,r]\n",
    "        \n",
    "        for d in range(k_f, k_f+k_dn):\n",
    "            alpha[n, d] += torch.sum(alpha_star[n,j]) * beta_weights[j,-1]\n",
    "\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dbs = run.fit(\n",
    "    x=m_dbs, \n",
    "    k_list=3, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=10, \n",
    "    # cluster=6, \n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_dbs.loc[[\"DBS4\"]], \n",
    "    hyperparameters={\"alpha_sigma\":.15, \"alpha_p_sigma\":1., \"alpha_p_conc0\":0.6, \n",
    "                     \"alpha_p_conc1\":0.6, \"alpha_rate\":1., \"pi_conc0\":0.5, \"alpha_conc\":100,\n",
    "                     \"scale_factor_alpha\":10000, \"scale_factor_centroid\":1000, \"scale_tau\":0},\n",
    "    enforce_sparsity = True, \n",
    "    reg_weight=0., \n",
    "    store_parameters = True, \n",
    "    seed_list=[92],\n",
    "    nonparametric=True,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sbs = obj_sbs.params[\"alpha\"] \n",
    "alpha_dbs = obj_dbs.params[\"alpha\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [alpha_sbs, alpha_dbs] \n",
    "input_tensor = [torch.tensor(alpha_sbs.values), torch.tensor(alpha_dbs.values)]\n",
    "max_shape = max([i.shape[1] for i in input_tensor])\n",
    "# stacked = torch.stack(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = run.fit(\n",
    "    alpha=input, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=3000,\n",
    "    cluster=5, \n",
    "    hyperparameters={\"alpha_sigma\":.15, \"alpha_p_sigma\":1., \"alpha_p_conc0\":0.6, \n",
    "                     \"alpha_p_conc1\":0.6, \"alpha_rate\":1., \"pi_conc0\":0.5, \"alpha_conc\":100,\n",
    "                     \"scale_factor_alpha\":10000, \"scale_factor_centroid\":1000, \"scale_tau\":0},\n",
    "    store_parameters = True, \n",
    "    seed_list=[92],\n",
    "    nonparametric=True,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def mix_weights(beta):\n",
    "    '''\n",
    "    Function used for the stick-breaking process.\n",
    "    '''\n",
    "    print(\"beta =\", beta)\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    print(\"beta1m_cumprod =\", beta1m_cumprod)\n",
    "    res1 = F.pad(beta, (0, 1), value=1)\n",
    "    res2 = F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "    res = res1 * res2\n",
    "    print(f\"res1 = {res1}, res2 = {res2}, res = {res}\\n\")\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 6\n",
    "with pyro.plate(\"beta_plate\", cluster-1):\n",
    "    pi_beta = pyro.sample(f\"beta\", pyro.distributions.Beta(1, 1.1755e-36))\n",
    "    # pi_beta = torch.tensor([1.1755e-36, 2.1648e-18, 1.1755e-36, 6.6389e-33, 1.1755e-36])\n",
    "    print(\"pi_beta =\", pi_beta)\n",
    "    pi = mix_weights(pi_beta)\n",
    "\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_star = torch.zeros(k_denovo, 96, dtype=torch.float64) \n",
    "for i in range(k_denovo):\n",
    "    tmp_sbs = torch.cat((ref_sbs, dn_sbs[i].unsqueeze(0)))\n",
    "    beta_star[i] = pi[i].unsqueeze(0).matmul(tmp_sbs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Gamma(0.01, 0.01).sample((5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Dirichlet(torch.ones(5)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - pyro.distributions.Beta(1, 1e-10).sample((cluster-1,))).cumprod(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = torch.zeros((10,))\n",
    "pi[:5] = 5\n",
    "pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_centr = mixture[0].params[\"alpha_prior\"]\n",
    "print(alpha_centr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.normalized_mutual_info_score(mixture.groups, g_sbs)) \n",
    "print(sklearn.metrics.normalized_mutual_info_score(mixture.groups, g_dbs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"scale_factor_centroid\"])\n",
    "print(obj_sbs.params[\"scale_factor_alpha\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.train_params[6][\"scale_factor_centroid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"pi_conc0\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(obj_sbs.likelihoods)), y=obj_sbs.likelihoods) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(obj_sbs.losses)), y=obj_sbs.losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"scale_factor_centroid_param\"])), \n",
    "                     y=obj_sbs.gradient_norms[\"scale_factor_centroid_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"scale_factor_alpha_param\"])), \n",
    "                     y=obj_sbs.gradient_norms[\"scale_factor_alpha_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha_prior_param\"])), y=obj_sbs.gradient_norms[\"alpha_prior_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha_prior_param\"])), y=obj_sbs.gradient_norms[\"alpha_prior_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"pi_param\"])), y=obj_sbs.gradient_norms[\"pi_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"pi_conc0_param\"])), y=obj_sbs.gradient_norms[\"pi_conc0_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha\"])), y=obj_sbs.gradient_norms[\"alpha\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"beta_denovo\"])), y=obj_sbs.gradient_norms[\"beta_denovo\"])\n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(obj_sbs.init_params[\"alpha_prior_param\"]), columns=obj_sbs.params[\"alpha\"].columns).plot.bar(stacked=True, legend=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: pd.DataFrame(np.array(obj_sbs.params[\"alpha_prior\"]), columns=obj_sbs.params[\"alpha_prior\"].columns).plot.bar(stacked=True, legend=False) \n",
    "except Exception as e: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for gid in set(np.array(obj_sbs.groups)):\n",
    "        tmp = [i for i, v in enumerate(obj_sbs.groups) if v == gid]\n",
    "        # tmp = [i for i, v in enumerate(obj_sbs.groups) if (v == gid and i in idxs)]\n",
    "        if len(tmp) == 0: continue\n",
    "        pd.DataFrame(np.array(obj_sbs.params[\"alpha\"]), columns=obj_sbs.params[\"alpha\"].columns, \n",
    "                     index=obj_sbs.params[\"alpha\"].index).iloc[tmp].plot.bar(stacked=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    obj_sbs.alpha.plot.bar(stacked=True, legend=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for sbs in pd.concat((obj_sbs.params[\"beta_f\"], obj_sbs.params[\"beta_d\"])).index:\n",
    "        pd.concat((obj_sbs.params[\"beta_f\"], obj_sbs.params[\"beta_d\"])).loc[[sbs]].transpose().plot.bar()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
