{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenab/Library/r-miniconda-arm64/envs/basilica-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pybasilica.run as run\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from pyro.distributions import constraints\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_weights(beta):\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "def model(data):\n",
    "    with pyro.plate(\"beta_plate\", T-1):\n",
    "        beta = pyro.sample(\"beta\",  dist.Beta(1, alpha))\n",
    "\n",
    "    with pyro.plate(\"mu_plate\", T):\n",
    "        mu = pyro.sample(\"mu\",  dist.MultivariateNormal(torch.zeros(2), 5 * torch.eye(2)))\n",
    "\n",
    "    with pyro.plate(\"data\", N):\n",
    "        z = pyro.sample(\"z\",  dist.Categorical(mix_weights(beta)))\n",
    "        pyro.sample(\"obs\",  dist.MultivariateNormal(mu[z], torch.eye(2)), obs=data)\n",
    "\n",
    "def guide(data):\n",
    "    kappa = pyro.param('kappa', lambda: dist.Uniform(0, 2).sample([T-1]), constraint=constraints.positive)\n",
    "    tau = pyro.param('tau', lambda: dist.MultivariateNormal(torch.zeros(2), 3 * torch.eye(2)).sample([T]))\n",
    "    phi = pyro.param('phi', lambda: dist.Dirichlet(1/T * torch.ones(T)).sample([N]), constraint=constraints.simplex)\n",
    "\n",
    "    with pyro.plate(\"beta_plate\", T-1):\n",
    "        q_beta = pyro.sample(\"beta\",  dist.Beta(torch.ones(T-1), kappa))\n",
    "\n",
    "    with pyro.plate(\"mu_plate\", T):\n",
    "        q_mu = pyro.sample(\"mu\",  dist.MultivariateNormal(tau, torch.eye(2)))\n",
    "\n",
    "    with pyro.plate(\"data\", N):\n",
    "        z = pyro.sample(\"z\",  dist.Categorical(phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat((dist.MultivariateNormal(-8 * torch.ones(2), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(8 * torch.ones(2), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(torch.tensor([1.5, 2]), torch.eye(2)).sample([50]),\n",
    "                  dist.MultivariateNormal(torch.tensor([-0.5, 1]), torch.eye(2)).sample([50])))\n",
    "\n",
    "N = data.shape[0]\n",
    "T = 6\n",
    "optim = pyro.optim.Adam({\"lr\": 0.05})\n",
    "svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO())\n",
    "losses = []\n",
    "\n",
    "def train(num_iterations):\n",
    "    pyro.clear_param_store()\n",
    "    for j in tqdm(range(num_iterations)):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "\n",
    "def truncate(alpha, centers, weights):\n",
    "    threshold = alpha**-1 / 100.\n",
    "    true_centers = centers[weights > threshold]\n",
    "    true_weights = weights[weights > threshold] / torch.sum(weights[weights > threshold])\n",
    "    return true_centers, true_weights\n",
    "\n",
    "alpha = 0.1\n",
    "train(1000)\n",
    "\n",
    "# We make a point-estimate of our model parameters using the posterior means of tau and phi for the centers and weights\n",
    "Bayes_Centers_01, Bayes_Weights_01 = truncate(alpha, pyro.param(\"tau\").detach(), \n",
    "                                              torch.mean(pyro.param(\"phi\").detach(), dim=0))\n",
    "\n",
    "alpha = 1.5\n",
    "train(1000)\n",
    "\n",
    "# We make a point-estimate of our model parameters using the posterior means of tau and phi for the centers and weights\n",
    "Bayes_Centers_15, Bayes_Weights_15 = truncate(alpha, pyro.param(\"tau\").detach(), \n",
    "                                              torch.mean(pyro.param(\"phi\").detach(), dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bayes_Weights_01)\n",
    "print(Bayes_Weights_15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_g = pd.read_csv(\"test_datasets/counts_sbs.N150.G3.csv\")\n",
    "m_sbs = m_g.drop([\"groups\"], axis=1)\n",
    "g_sbs = m_g[\"groups\"].tolist() \n",
    "cosmic_sbs = pd.read_csv(\"test_datasets/COSMIC_filt.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_g = pd.read_csv(\"test_datasets/counts_dbs.N150.G3.csv\")\n",
    "m_dbs = m_g.drop([\"groups\"], axis=1)\n",
    "g_dbs = m_g[\"groups\"].tolist()\n",
    "cosmic_dbs = pd.read_csv(\"test_datasets/COSMIC_dbs.csv\", index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9031, 0.7285, 0.6458, 1.0000, 1.0000])\n",
      "tensor([90.,  7.,  2.,  1.,  0.,  0.])\n",
      "tensor([0.0183, 0.7627, 0.9953, 1.0000, 1.0000])\n",
      "tensor([ 2., 75., 23.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "dn_sbs = torch.tensor(cosmic_sbs.loc[[\"SBS6\",\"SBS17b\"]].values, dtype=torch.float64)\n",
    "ref_sbs = torch.tensor(cosmic_sbs.loc[[\"SBS1\",\"SBS2\",\"SBS5\"]].values, dtype=torch.float64)\n",
    "# k_denovo = dn_sbs.shape[0]\n",
    "# k_fixed = ref_sbs.shape[0]\n",
    "clusters = 6\n",
    "\n",
    "def mix_weights(beta):\n",
    "    '''\n",
    "    Function used for the stick-breaking process.\n",
    "    '''\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "\n",
    "conc = torch.tensor([0.36432, 0.383313626, 0.257168233, 0.005969330, 0.017175399])\n",
    "\n",
    "pi_beta = torch.zeros(len(conc))\n",
    "for i in range(len(conc)):\n",
    "    pi_beta[i] = pyro.sample(\"beta\", pyro.distributions.Beta(1, conc[i])) \n",
    "\n",
    "pi = mix_weights(pi_beta)\n",
    "\n",
    "print(pi_beta)\n",
    "print(torch.round(pi * 100))\n",
    "\n",
    "with pyro.plate(\"beta_d_plate\", len(conc)):\n",
    "    pi_beta2 = pyro.sample(\"beta\", pyro.distributions.Beta(1, conc)) \n",
    "\n",
    "print(pi_beta2)\n",
    "pi2 = mix_weights(pi_beta2)\n",
    "print(torch.round(pi2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(dist.Gamma(torch.tensor(0.2, dtype=torch.float64), 0.1).sample((1000,)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.round(dist.Dirichlet(torch.tensor([0.3, 0.5, 0.3])*10).sample((10,)), decimals=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.tensor([1.,2.,3.]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO 49954.599999: 100%|██████████| 2000/2000 [00:06<00:00, 319.57it/s]\n",
      "ELBO 46872.140686: 100%|██████████| 2000/2000 [00:06<00:00, 306.38it/s]\n"
     ]
    }
   ],
   "source": [
    "obj_sbs = run.fit(\n",
    "    x=m_sbs, \n",
    "    k_list=[3,4], \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=2000, \n",
    "    # cluster=[3],\n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_sbs.loc[[\"SBS1\",\"SBS5\"]], \n",
    "    store_parameters = True, \n",
    "    seed_list=[30],\n",
    "    nonparametric=False,\n",
    "    store_fits=True, enumer=\"parallel\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO 132427.058856: 100%|██████████| 1000/1000 [00:02<00:00, 333.48it/s]\n"
     ]
    }
   ],
   "source": [
    "obj_dbs = run.fit(\n",
    "    x=m_dbs, \n",
    "    k_list=3, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=1000, \n",
    "    # cluster=[3],\n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_dbs.loc[[\"DBS3\",\"DBS5\"]], \n",
    "    store_parameters = True, \n",
    "    seed_list=[30],\n",
    "    nonparametric=False,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bar desc:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO -13432.927245: 100%|██████████| 1000/1000 [00:02<00:00, 361.99it/s]\n"
     ]
    }
   ],
   "source": [
    "input_alpha = [obj_sbs.params[\"alpha\"], obj_dbs.params[\"alpha\"]]\n",
    "obj_clust = run.fit(\n",
    "    alpha=input_alpha,\n",
    "    lr=0.005, \n",
    "    # optim_gamma=0.1,\n",
    "    n_steps=1000, \n",
    "    cluster=[1],\n",
    "    store_parameters=False, \n",
    "    hyperparameters={\"scale_factor_alpha\":1,\n",
    "                     \"scale_factor_centroid\":1000},\n",
    "    seed_list=[30],\n",
    "    nonparametric=False,\n",
    "    store_fits=True, \n",
    "    # enumer=\"sequential\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'labels_pred' parameter of normalized_mutual_info_score must be an array-like. Got None instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/elenab/GitHub/pybasilica/test.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elenab/GitHub/pybasilica/test.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fitted_grps \u001b[39m=\u001b[39m obj_clust\u001b[39m.\u001b[39mgroups \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elenab/GitHub/pybasilica/test.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m init_grps \u001b[39m=\u001b[39m obj_clust\u001b[39m.\u001b[39minit_params[\u001b[39m\"\u001b[39m\u001b[39minit_clusters\u001b[39m\u001b[39m\"\u001b[39m] \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elenab/GitHub/pybasilica/test.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sklearn\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mnormalized_mutual_info_score(fitted_grps, init_grps) \n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/envs/basilica-env/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:201\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m to_ignore \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    199\u001b[0m params \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 201\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    202\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39;49mfunc\u001b[39m.\u001b[39;49m\u001b[39m__qualname__\u001b[39;49m\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/envs/basilica-env/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'labels_pred' parameter of normalized_mutual_info_score must be an array-like. Got None instead."
     ]
    }
   ],
   "source": [
    "fitted_grps = obj_clust.groups \n",
    "init_grps = obj_clust.init_params[\"init_clusters\"] \n",
    "sklearn.metrics.normalized_mutual_info_score(fitted_grps, init_grps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha_prior': array([[3.09356898e-01, 7.23796897e-03, 1.64192199e-04, 4.61899303e-03,\n",
       "         2.57856399e-03, 6.76043391e-01, 1.94365196e-02, 1.13202147e-02,\n",
       "         4.19796288e-01, 4.70661074e-01, 7.87859038e-02, 1.17549435e-38],\n",
       "        [2.32092232e-01, 2.54470054e-02, 7.35509038e-01, 2.73319194e-03,\n",
       "         1.04476203e-05, 4.20813356e-03, 2.59973705e-01, 1.30015807e-02,\n",
       "         6.36480972e-02, 8.61725062e-02, 5.77204108e-01, 1.17549435e-38],\n",
       "        [2.45857686e-01, 1.59027260e-02, 6.10817969e-01, 6.32758811e-03,\n",
       "         9.62918699e-02, 2.48020757e-02, 4.94775325e-02, 5.21353371e-02,\n",
       "         5.36355555e-01, 2.40847722e-01, 1.21183850e-01, 1.17549435e-38]]),\n",
       " 'pi': array([0.32037163, 0.48040223, 0.19922613]),\n",
       " 'latent_class': array([[1.00000000e+00, 5.39649705e-13, 4.00152592e-17],\n",
       "        [8.38880986e-03, 9.91611183e-01, 1.13019205e-10],\n",
       "        [4.73527275e-02, 3.20487261e-01, 6.32160187e-01],\n",
       "        [3.91969894e-04, 7.67805716e-07, 9.99607146e-01],\n",
       "        [1.00000000e+00, 8.15066263e-14, 1.47082811e-16],\n",
       "        [3.33718308e-05, 9.99966621e-01, 2.24179626e-08],\n",
       "        [3.72553593e-03, 7.85630436e-06, 9.96266663e-01],\n",
       "        [2.43000398e-09, 9.99341488e-01, 6.58516190e-04],\n",
       "        [4.97193821e-03, 9.95028496e-01, 1.53080377e-22],\n",
       "        [2.55581537e-12, 9.99837875e-01, 1.62471799e-04],\n",
       "        [6.65694062e-12, 7.82905153e-13, 1.00000000e+00],\n",
       "        [9.97498035e-01, 7.87280352e-10, 2.50197481e-03],\n",
       "        [2.38087421e-04, 9.99761581e-01, 9.69570764e-14],\n",
       "        [4.71688151e-01, 5.28311789e-01, 1.40617393e-10],\n",
       "        [5.02360761e-01, 4.97639239e-01, 5.26016784e-13],\n",
       "        [1.12891989e-08, 1.00000000e+00, 4.69593867e-18],\n",
       "        [9.99965668e-01, 3.41827763e-05, 1.59045682e-12],\n",
       "        [2.94357077e-24, 1.00000000e+00, 8.70140444e-19],\n",
       "        [1.90138067e-07, 9.99999046e-01, 6.81687027e-07],\n",
       "        [9.99857903e-01, 6.33888485e-05, 7.86600212e-05],\n",
       "        [1.31762129e-10, 1.00000000e+00, 5.70903431e-08],\n",
       "        [9.94530439e-01, 5.46807609e-03, 1.52849680e-06],\n",
       "        [2.96575126e-06, 9.99995232e-01, 1.94084964e-06],\n",
       "        [2.34115490e-07, 1.00000000e+00, 4.44173517e-11],\n",
       "        [3.86075314e-08, 1.04007930e-04, 9.99896049e-01],\n",
       "        [9.96184707e-01, 2.81851040e-03, 9.96833434e-04],\n",
       "        [7.69562178e-07, 9.99926567e-01, 7.27373190e-05],\n",
       "        [5.47392298e-14, 1.00000000e+00, 5.47902521e-16],\n",
       "        [4.77258936e-02, 1.54515967e-01, 7.97758162e-01],\n",
       "        [1.11327503e-10, 9.94396687e-01, 5.60374046e-03],\n",
       "        [1.00000000e+00, 9.87426141e-09, 5.41602047e-23],\n",
       "        [2.84132167e-08, 9.99974728e-01, 2.54272290e-05],\n",
       "        [1.16368726e-01, 8.55537057e-01, 2.80943047e-02],\n",
       "        [4.40406555e-04, 1.80157120e-04, 9.99379337e-01],\n",
       "        [4.81523372e-12, 7.28343666e-01, 2.71655977e-01],\n",
       "        [1.09497339e-20, 1.42344225e-09, 1.00000000e+00],\n",
       "        [1.23417057e-01, 1.01613916e-15, 8.76582563e-01],\n",
       "        [9.21038687e-01, 7.89554641e-02, 5.98232691e-06],\n",
       "        [9.99893785e-01, 1.06189967e-04, 3.20113588e-11],\n",
       "        [5.63395608e-10, 4.31910843e-01, 5.68089187e-01],\n",
       "        [4.53399589e-05, 9.99858856e-01, 9.59585232e-05],\n",
       "        [1.00000000e+00, 6.29501287e-08, 4.47820263e-15],\n",
       "        [1.85610037e-02, 9.81357574e-01, 8.14773957e-05],\n",
       "        [7.93055442e-18, 1.00000000e+00, 1.70318724e-11],\n",
       "        [9.73328352e-01, 5.48271753e-04, 2.61235721e-02],\n",
       "        [3.10133728e-05, 9.99969006e-01, 2.65538036e-10],\n",
       "        [1.00000000e+00, 5.55563373e-09, 3.00880165e-18],\n",
       "        [7.22774165e-03, 9.92737710e-01, 3.45771041e-05],\n",
       "        [5.09866242e-16, 1.46488859e-14, 1.00000000e+00],\n",
       "        [2.78666097e-17, 1.00000000e+00, 1.42102340e-19],\n",
       "        [8.73529967e-14, 1.00000000e+00, 1.70318793e-14],\n",
       "        [5.65287217e-20, 1.02852437e-05, 9.99990463e-01],\n",
       "        [6.85088040e-08, 3.47485719e-03, 9.96525168e-01],\n",
       "        [8.13875496e-01, 1.86080411e-01, 4.41304583e-05],\n",
       "        [6.02327771e-02, 9.39767003e-01, 7.15154727e-08],\n",
       "        [9.99993801e-01, 3.66161146e-07, 6.11145106e-06],\n",
       "        [1.00000000e+00, 7.25715795e-20, 2.73326596e-22],\n",
       "        [1.25764668e-01, 8.74213278e-01, 2.22617255e-05],\n",
       "        [7.28282845e-04, 9.99270916e-01, 7.18882518e-07],\n",
       "        [9.28031147e-01, 4.16033715e-03, 6.78084716e-02],\n",
       "        [7.01658973e-06, 9.99992847e-01, 4.35476322e-10],\n",
       "        [9.99996901e-01, 3.79748277e-09, 3.23905397e-06],\n",
       "        [1.38719947e-09, 1.00000000e+00, 2.02563896e-07],\n",
       "        [5.14899170e-07, 3.89063498e-03, 9.96108949e-01],\n",
       "        [4.00503183e-07, 9.99998450e-01, 1.13733699e-06],\n",
       "        [9.99994993e-01, 1.01108959e-07, 4.91743731e-06],\n",
       "        [2.28015613e-03, 9.93495226e-01, 4.22425149e-03],\n",
       "        [1.00000000e+00, 7.13165218e-14, 2.27066632e-09],\n",
       "        [1.10709675e-09, 1.00000000e+00, 9.93747836e-13],\n",
       "        [1.00000000e+00, 2.60008248e-12, 7.49949713e-10],\n",
       "        [2.80744132e-07, 9.99900460e-01, 9.92744099e-05],\n",
       "        [5.72861219e-03, 8.25904131e-01, 1.68367252e-01],\n",
       "        [3.45345815e-15, 1.00000000e+00, 3.98468000e-24],\n",
       "        [9.99839067e-01, 1.60893193e-04, 1.17235321e-09],\n",
       "        [9.47734058e-01, 4.06341982e-08, 5.22658937e-02],\n",
       "        [9.80224371e-01, 2.24877167e-05, 1.97530091e-02],\n",
       "        [6.93390250e-01, 3.06609482e-01, 1.26116972e-09],\n",
       "        [1.20621640e-02, 5.27685273e-08, 9.87937689e-01],\n",
       "        [4.00976419e-01, 1.83442353e-06, 5.99021912e-01],\n",
       "        [5.08476019e-01, 4.58022654e-02, 4.45721626e-01],\n",
       "        [9.97752547e-01, 2.28682638e-05, 2.22459482e-03],\n",
       "        [9.86687899e-01, 1.32597154e-02, 5.23425806e-05],\n",
       "        [9.92346406e-01, 7.65358238e-03, 5.88563434e-11],\n",
       "        [1.38101028e-03, 9.98619080e-01, 4.18268588e-12],\n",
       "        [1.16505000e-10, 2.49867771e-08, 1.00000000e+00],\n",
       "        [4.67910866e-12, 9.99998093e-01, 1.77708409e-06],\n",
       "        [9.96582627e-01, 3.41722835e-03, 5.32075317e-09],\n",
       "        [8.50895667e-05, 9.99775887e-01, 1.39478158e-04],\n",
       "        [2.80995727e-01, 7.09218442e-01, 9.78580397e-03],\n",
       "        [2.97073970e-13, 1.00000000e+00, 2.31406646e-19],\n",
       "        [1.00000000e+00, 5.57730029e-10, 1.69547809e-09],\n",
       "        [9.99990344e-01, 9.70861765e-06, 1.43930062e-10],\n",
       "        [4.07997817e-01, 2.61434406e-01, 3.30567598e-01],\n",
       "        [2.78463988e-11, 1.00000000e+00, 2.14993930e-12],\n",
       "        [2.37121580e-16, 2.65013307e-01, 7.34986424e-01],\n",
       "        [9.99948502e-01, 5.16047548e-05, 6.51132481e-11],\n",
       "        [2.30951812e-02, 9.76604044e-01, 3.00629326e-04],\n",
       "        [1.36901885e-01, 8.63098204e-01, 4.99717672e-08],\n",
       "        [7.34285322e-06, 1.39458612e-01, 8.60534012e-01],\n",
       "        [6.69418229e-03, 9.93305802e-01, 6.02885172e-11],\n",
       "        [4.10345438e-11, 1.00000000e+00, 2.85525908e-10],\n",
       "        [9.99868751e-01, 7.28583564e-06, 1.23948237e-04],\n",
       "        [5.13031706e-03, 9.94870067e-01, 1.67700502e-08],\n",
       "        [1.85063231e-09, 1.00000000e+00, 8.04084142e-15],\n",
       "        [3.16792356e-11, 1.00000000e+00, 2.11174733e-13],\n",
       "        [1.36105465e-02, 9.86389399e-01, 7.69723590e-11],\n",
       "        [1.01945043e-01, 7.69797899e-03, 8.90357018e-01],\n",
       "        [1.00000000e+00, 7.80751514e-25, 2.54212584e-26],\n",
       "        [1.15983376e-05, 9.99718964e-01, 2.69433571e-04],\n",
       "        [5.70252382e-07, 9.99999046e-01, 1.17698917e-12],\n",
       "        [4.60354893e-10, 8.16992213e-07, 9.99999046e-01],\n",
       "        [9.99972343e-01, 2.74509985e-05, 2.30736362e-07],\n",
       "        [5.24295643e-02, 9.30223346e-01, 1.73471011e-02],\n",
       "        [6.40268709e-08, 9.21557963e-01, 7.84418657e-02],\n",
       "        [1.86651378e-05, 9.13234890e-01, 8.67463052e-02],\n",
       "        [7.28162766e-01, 2.71837324e-01, 5.54373006e-11],\n",
       "        [1.00000000e+00, 1.43728432e-10, 2.94480111e-20],\n",
       "        [5.14596868e-16, 1.00000000e+00, 4.00447109e-18],\n",
       "        [1.00000000e+00, 1.71055721e-08, 4.58462011e-07],\n",
       "        [6.14925680e-20, 1.00000000e+00, 2.67656757e-15],\n",
       "        [1.54250007e-12, 1.00000000e+00, 2.17621606e-23],\n",
       "        [4.75237146e-03, 9.95225430e-01, 2.21943355e-05],\n",
       "        [3.16663335e-13, 1.36396245e-08, 1.00000000e+00],\n",
       "        [3.63651593e-17, 1.00000000e+00, 1.49082196e-20],\n",
       "        [1.77918675e-08, 9.99591410e-01, 4.08754102e-04],\n",
       "        [4.86211618e-03, 9.95137870e-01, 2.73136060e-13],\n",
       "        [7.08826212e-03, 9.86602724e-01, 6.30894769e-03],\n",
       "        [2.12269589e-01, 7.87713587e-01, 1.71791817e-05],\n",
       "        [1.09679799e-09, 4.25854942e-08, 1.00000000e+00],\n",
       "        [9.85185802e-01, 1.48141496e-02, 4.42066330e-08],\n",
       "        [6.72196562e-04, 9.99320865e-01, 6.95793733e-06],\n",
       "        [1.00000000e+00, 1.30946507e-08, 2.69426065e-10],\n",
       "        [1.00000000e+00, 1.90231043e-17, 5.46969628e-14],\n",
       "        [1.73453031e-07, 9.99967575e-01, 3.25053625e-05],\n",
       "        [1.01457254e-11, 2.16930475e-05, 9.99978065e-01],\n",
       "        [4.01589088e-03, 5.43517344e-05, 9.95929778e-01],\n",
       "        [2.21556784e-05, 9.99977112e-01, 4.24910523e-23],\n",
       "        [7.73315085e-03, 9.92116690e-01, 1.50124062e-04],\n",
       "        [9.99999046e-01, 7.18269860e-07, 4.04656902e-07],\n",
       "        [1.78246334e-13, 9.45728272e-02, 9.05427516e-01],\n",
       "        [9.99539495e-01, 4.60091629e-04, 2.06473120e-12],\n",
       "        [3.31161812e-12, 1.00000000e+00, 3.07735892e-10],\n",
       "        [8.11732814e-09, 1.00000000e+00, 2.87843990e-20],\n",
       "        [1.28779802e-05, 9.33732665e-08, 9.99986649e-01],\n",
       "        [1.68078745e-11, 2.27238547e-06, 9.99998093e-01],\n",
       "        [4.72209811e-01, 2.64992937e-03, 5.25140107e-01],\n",
       "        [3.15709668e-03, 9.96842623e-01, 3.04503907e-08],\n",
       "        [1.18913558e-05, 3.47857072e-04, 9.99640286e-01],\n",
       "        [1.73558590e-09, 4.21928839e-08, 1.00000000e+00],\n",
       "        [6.09949457e-05, 4.73015767e-12, 9.99938965e-01]]),\n",
       " 'init_clusters': array([2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_clust.init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32037163 0.48040223 0.19922613]\n",
      "[0.24832506 0.60452432 0.14715062]\n"
     ]
    }
   ],
   "source": [
    "print(obj_clust.init_params[\"pi\"])\n",
    "print(obj_clust.params[\"pi\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 0 2 2 2 2 2 2 2 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1\n",
      " 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(obj_clust.groups) \n",
    "print(obj_clust.init_params[\"init_clusters\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.813763e-06</td>\n",
       "      <td>4.598606e-07</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.278157e-06</td>\n",
       "      <td>8.228630e-07</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.964098e-05</td>\n",
       "      <td>7.995612e-07</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.595536e-06</td>\n",
       "      <td>5.839855e-07</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.915339e-06</td>\n",
       "      <td>2.463153e-06</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.162418e-07</td>\n",
       "      <td>1.232728e-04</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>8.909166e-07</td>\n",
       "      <td>7.659577e-05</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>9.787764e-07</td>\n",
       "      <td>2.687341e-05</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.087666e-06</td>\n",
       "      <td>1.957569e-04</td>\n",
       "      <td>0.999803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.240030e-06</td>\n",
       "      <td>2.850948e-05</td>\n",
       "      <td>0.999970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1         2\n",
       "0    2.813763e-06  4.598606e-07  0.999997\n",
       "1    3.278157e-06  8.228630e-07  0.999996\n",
       "2    1.964098e-05  7.995612e-07  0.999980\n",
       "3    9.595536e-06  5.839855e-07  0.999990\n",
       "4    1.915339e-06  2.463153e-06  0.999996\n",
       "..            ...           ...       ...\n",
       "145  6.162418e-07  1.232728e-04  0.999876\n",
       "146  8.909166e-07  7.659577e-05  0.999923\n",
       "147  9.787764e-07  2.687341e-05  0.999972\n",
       "148  1.087666e-06  1.957569e-04  0.999803\n",
       "149  1.240030e-06  2.850948e-05  0.999970\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_clust.params[\"post_probs\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "import numpy as np\n",
    "\n",
    "# model\n",
    "def model(data, K):\n",
    "    N = len(data)\n",
    "    hidden_dim = 2\n",
    "\n",
    "    # As in any clustering algorithm, the mixing proportions are the assignment probabilities of the cells.\n",
    "    # We sample the mixture weights from a Dirichlet distribution\n",
    "\n",
    "    weights = pyro.sample('mixture_weights', dist.Dirichlet(torch.ones(K)))\n",
    "\n",
    "    with pyro.plate('probabilities', K):  # cat_probs.size=(K,hidden_dim)\n",
    "        cat_probs = pyro.sample(\"cat_probabilities\", dist.Dirichlet(torch.ones(hidden_dim)))\n",
    "\n",
    "    cat_vector = torch.tensor(np.arange(hidden_dim) + 1, dtype=torch.float)\n",
    "    scale = pyro.sample(\"scale\", dist.Gamma(5, 1))\n",
    "\n",
    "    # likelihood\n",
    "    with pyro.plate(\"data\", N):\n",
    "        pyro.factor(\"lk\", log_lik(data, scale, weights, cat_vector, cat_probs, K))\n",
    "\n",
    "\n",
    "# loglikelihood\n",
    "def log_lik(data, scale, weights, cat_vector, cat_probs, K):\n",
    "    N = len(data)\n",
    "    hidden_dim = 2\n",
    "    data = data.reshape(N, 1, 1)\n",
    "    mean = scale * cat_vector.reshape(1, 1, hidden_dim)\n",
    "    weights = weights.reshape(1, K, 1)\n",
    "    cat_probs = cat_probs.reshape(1, K, hidden_dim)\n",
    "\n",
    "    lk = torch.log(weights) + dist.Poisson(mean).log_prob(data) + torch.log(cat_probs)\n",
    "    c = torch.max(torch.max(lk, dim=-1).values, dim=-1).values.reshape(N, 1, 1)\n",
    "    log_lik = c + torch.log(torch.exp(lk - c).sum(dim=-1).sum(dim=-1)).reshape(N, 1, 1)\n",
    "\n",
    "    return log_lik.sum()\n",
    "\n",
    "\n",
    "# guide\n",
    "def guide(data, K):\n",
    "    pi = pyro.param(\"q_mixture_weights\", create_params(data, K)[\"mixture_weights\"], constraint=constraints.simplex)\n",
    "    scale = pyro.param(\"q_scale\", create_params(data, K)[\"scale\"], constraint=constraints.positive)\n",
    "    probs = pyro.param(\"q_cat_probabilities\", create_params(data, K)[\"cat_probabilities\"],\n",
    "                       constraint=constraints.simplex)\n",
    "\n",
    "    print(probs)\n",
    "\n",
    "    with pyro.plate('probabilities', K):  # cat_probs.size=(K,hidden_dim)\n",
    "        cat_prob = pyro.sample(\"cat_probabilities\", dist.Delta(probs).to_event(1))\n",
    "    pyro.sample('mixture_weights', dist.Delta(pi).to_event(1))\n",
    "    pyro.sample(\"scale\", dist.Delta(scale))\n",
    "\n",
    "\n",
    "# initialization\n",
    "def create_params(data, K):\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    N = len(data)\n",
    "    hidden_dim = 2\n",
    "\n",
    "    kmeans = KMeans(init=\"random\",\n",
    "                    n_clusters=K,\n",
    "                    n_init=10,\n",
    "                    max_iter=300,\n",
    "                    random_state=42)\n",
    "\n",
    "    kmeans.fit(data.reshape(N, 1))\n",
    "\n",
    "    categorical = torch.tensor(np.arange(hidden_dim) + 1, dtype=torch.float)\n",
    "    mean_categorical = categorical.mean()\n",
    "    mean_clusters = kmeans.cluster_centers_.mean()\n",
    "\n",
    "    # initialize scale\n",
    "    scale = mean_clusters / mean_categorical\n",
    "    mean = scale * categorical.reshape(1, hidden_dim)\n",
    "\n",
    "    # initialize mixing proportions and cat_probs\n",
    "    Prob = torch.ones(K, hidden_dim) / hidden_dim\n",
    "    mixing_proportions = torch.ones(K) / K\n",
    "\n",
    "    for k in range(K):\n",
    "        subset = []\n",
    "        for i in range(len(data)):\n",
    "            if kmeans.labels_[i] == k:\n",
    "                subset.append(data[i])\n",
    "\n",
    "        n = len(subset)\n",
    "        dataset = torch.tensor(subset).reshape(n, 1)\n",
    "        mixing_proportions[k] = len(subset) / len(data)\n",
    "\n",
    "        p = dist.Poisson(mean).log_prob(dataset)\n",
    "        c = torch.max(p, dim=0).values.reshape(1, hidden_dim)\n",
    "        p = c + torch.log(torch.exp(p - c).sum(dim=0)).reshape(1, hidden_dim)\n",
    "        c = torch.max(p, dim=-1).values\n",
    "        Norm = c + torch.log(torch.exp(p - c).sum(dim=-1))\n",
    "        Prob[k] = torch.exp(p - Norm)\n",
    "\n",
    "    params = {\"mixture_weights\": mixing_proportions, \"scale\": scale, \"cat_probabilities\": Prob}\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "# cluster assignments\n",
    "def cluster_assignments(data, K, pi, scale, categorical):\n",
    "    N = len(data)\n",
    "\n",
    "    mean = scale * categorical.reshape(1, K)\n",
    "    pi = pi.reshape(1, K)\n",
    "    data = data.reshape(N, 1)\n",
    "\n",
    "    Prob = torch.log(pi) + dist.Poisson(mean).log_prob(data)  # Prob.size=(N,K)\n",
    "    c = torch.max(Prob, dim=-1).values.reshape(N, 1)\n",
    "    Norm = c + torch.log(torch.exp(Prob - c).sum(dim=-1)).reshape(N, 1)  # Norm.size= (N,1)\n",
    "\n",
    "    return torch.exp(Prob - Norm)\n",
    "\n",
    "\n",
    "#inference\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "def inference(model,guide,K,data,lr=0.05,num_steps=500):\n",
    "\n",
    "    pyro.clear_param_store()  # always clear the store before the inference\n",
    "\n",
    "    # learning global parameters\n",
    "    adam_params = {\"lr\": lr}\n",
    "    optimizer = Adam(adam_params)\n",
    "    elbo = Trace_ELBO()\n",
    "\n",
    "    svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "    # inference\n",
    "    # do gradient steps\n",
    "    for step in range(num_steps):\n",
    "        loss = svi.step(data, K)  # get the loss function after a gradient step\n",
    "        if step % 10 == 0:\n",
    "            print(\"loss =\", loss)  # check the progress\n",
    "\n",
    "    print(\"final loss =\", svi.evaluate_loss(data, K))\n",
    "\n",
    "    parameters = {}\n",
    "    for key in pyro.get_param_store().get_all_param_names():\n",
    "        parameters.update({key: torch.tensor(pyro.param(key))})\n",
    "\n",
    "    \n",
    "    cat_probs = parameters[\"q_cat_probabilities\"]\n",
    "    scale = parameters[\"q_scale\"]\n",
    "    pi = parameters[\"q_mixture_weights\"]\n",
    "    categorical = torch.argmax(cat_probs, dim=-1) + 1\n",
    "    assignment_probs = cluster_assignments(data, K, pi, scale, categorical)\n",
    "    assignments = torch.argmax(assignment_probs, dim=-1)\n",
    "    parameters.update({\"categorical_variable\":categorical, \n",
    "                       \"assignment_probs\":assignment_probs,\n",
    "                       \"assignments\":assignments})\n",
    "\n",
    "    # print(\"parameters:\", parameters)\n",
    "    # print(\"categorical variable:\", categorical)\n",
    "    # print(\"assignment_probs:\", assignment_probs)\n",
    "    # print(\"assignments\", assignments)\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotting(data, K, assignments, bins=20):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(12, 10), sharey=True)\n",
    "    for k in range(K):\n",
    "        subset = []\n",
    "        for i in range(len(data)):\n",
    "            if assignments[i] == k:\n",
    "                subset.append(data[i])\n",
    "\n",
    "        dataset = torch.tensor(subset)\n",
    "        axes.hist(dataset, bins=bins, fill=True)\n",
    "\n",
    "\n",
    "#data generator\n",
    "def data_generator(N, scale, categorical, mixing_proportions):\n",
    "    data = []\n",
    "    means = scale * categorical\n",
    "\n",
    "    for n in range(N):\n",
    "        cluster = dist.Categorical(mixing_proportions).sample()\n",
    "        data.append(dist.Poisson(means[cluster]).sample())\n",
    "\n",
    "    data = torch.tensor(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "N = 1000\n",
    "scale = 5\n",
    "categorical = torch.tensor([1.,5.])\n",
    "K = len(categorical)\n",
    "mixing_proportions = torch.tensor([0.3,0.7])\n",
    "data = data_generator(N, scale, categorical, mixing_proportions)\n",
    "\n",
    "inferred_parameters = inference(model, guide, K, data, lr=0.05, num_steps=3)\n",
    "assignments = inferred_parameters[\"assignments\"]\n",
    "plotting(data, K, assignments, bins=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inferred_parameters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_parameters[\"q_cat_probabilities\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet\n",
    "\n",
    "# Define the parameters\n",
    "alpha = [1, 1, 1]  # Adjust alpha values as needed\n",
    "power = 2.0  # Adjust the power parameter\n",
    "\n",
    "# Sample from the standard Dirichlet distribution\n",
    "sample = np.random.dirichlet(alpha)\n",
    "\n",
    "# Apply the transformation\n",
    "sample_away_from_mode = sample ** (1 / power)\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sample_away_from_mode)\n",
    "print(\"Sampled:\", sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# Define the parameters of the Dirichlet distribution\n",
    "alpha = torch.tensor([1.0, 5.0, 1.0])  # Replace with your alpha values\n",
    "\n",
    "# Sample from the Dirichlet distribution\n",
    "sampled_value = pyro.sample(\"sampled_value\", dist.Dirichlet(alpha))\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sampled_value)\n",
    "\n",
    "# Find the mode of the Dirichlet distribution\n",
    "mode = torch.argmax(alpha)\n",
    "\n",
    "print(\"Mode\", mode)\n",
    "\n",
    "# Create a mask to zero out the mode value\n",
    "mask = torch.ones_like(sampled_value)\n",
    "mask[mode] = 0\n",
    "\n",
    "# Zero out the mode value\n",
    "sampled_value = sampled_value * mask\n",
    "\n",
    "# Renormalize to make it a valid probability distribution\n",
    "sampled_value = sampled_value / sampled_value.sum()\n",
    "\n",
    "print(\"Sampled value away from the mode:\", sampled_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = a_orig**(3)\n",
    "fig2, ax2 = plt.subplots()\n",
    "fig3, ax3 = plt.subplots()\n",
    "sns.histplot(a[:,0].tolist(), ax=ax2)\n",
    "sns.histplot(a[:,1].tolist(), ax=ax3)\n",
    "ax2.set_xlim(0,1)\n",
    "ax3.set_xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(fixed, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = torch.tensor(obj_sbs.beta_fixed.values)\n",
    "beta_w = torch.tensor(obj_sbs.params[\"beta_w\"].values)\n",
    "denovo = torch.tensor(obj_sbs.params[\"beta_d\"].values)\n",
    "cum_weights = torch.ones((obj_sbs.k_denovo, obj_sbs.k_fixed))/obj_sbs.k_fixed\n",
    "\n",
    "fixed_cum = obj_sbs._get_unique_beta_stick_breaking(beta_fixed=fixed, beta_denovo=None, beta_weights=cum_weights)\n",
    "fixed_cum = obj_sbs._norm_and_clamp(fixed_cum)\n",
    "\n",
    "print(torch.sum((fixed_cum * (torch.abs(fixed_cum - denovo)))) * torch.tensor(obj_sbs.x.values).sum())\n",
    "print(torch.sum((fixed_cum * (torch.abs(fixed_cum - denovo)))) * obj_sbs.x.shape[0] * obj_sbs.x.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obj_sbs.train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Dirichlet(fixed_cum*1000).log_prob(denovo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.gradient_norms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (1 - torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.x.sum() * torch.sum(beta_fixed_cum * (torch.abs(beta_fixed_cum - beta_denovo)))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## self.n_samples * self.contexts * pyro.distributions.Dirichlet(beta_fixed_cum*1000).to_event(1).log_prob(beta_denovo))\n",
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.param(\"beta_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_w\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.gradient_norms.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"alpha\"].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_dn = 2\n",
    "k_f = 3\n",
    "n_samples = 5\n",
    "beta_weights = pyro.distributions.Dirichlet(torch.ones(k_dn, k_f+1)).sample()\n",
    "alpha_star = pyro.distributions.Dirichlet(torch.ones(n_samples, k_dn)).sample()\n",
    "print(\"beta weights\\n\", beta_weights)\n",
    "print(\"alpha star\\n\", alpha_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_weights[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.zeros((n_samples, k_dn+k_f))\n",
    "\n",
    "for n in range(n_samples):\n",
    "    for j in range(k_dn):\n",
    "        for r in range(k_f):\n",
    "            alpha[n, r] += torch.sum(alpha_star[n,j]) * beta_weights[j,r]\n",
    "        \n",
    "        for d in range(k_f, k_f+k_dn):\n",
    "            alpha[n, d] += torch.sum(alpha_star[n,j]) * beta_weights[j,-1]\n",
    "\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"beta_d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dbs = run.fit(\n",
    "    x=m_dbs, \n",
    "    k_list=3, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=10, \n",
    "    # cluster=6, \n",
    "    dirichlet_prior=True,\n",
    "    beta_fixed=cosmic_dbs.loc[[\"DBS4\"]], \n",
    "    hyperparameters={\"alpha_sigma\":.15, \"alpha_p_sigma\":1., \"alpha_p_conc0\":0.6, \n",
    "                     \"alpha_p_conc1\":0.6, \"alpha_rate\":1., \"pi_conc0\":0.5, \"alpha_conc\":100,\n",
    "                     \"scale_factor_alpha\":10000, \"scale_factor_centroid\":1000, \"scale_tau\":0},\n",
    "    enforce_sparsity = True, \n",
    "    reg_weight=0., \n",
    "    store_parameters = True, \n",
    "    seed_list=[92],\n",
    "    nonparametric=True,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sbs = obj_sbs.params[\"alpha\"] \n",
    "alpha_dbs = obj_dbs.params[\"alpha\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [alpha_sbs, alpha_dbs] \n",
    "input_tensor = [torch.tensor(alpha_sbs.values), torch.tensor(alpha_dbs.values)]\n",
    "max_shape = max([i.shape[1] for i in input_tensor])\n",
    "# stacked = torch.stack(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = run.fit(\n",
    "    alpha=input, \n",
    "    lr=0.005, \n",
    "    optim_gamma=0.1,\n",
    "    n_steps=3000,\n",
    "    cluster=5, \n",
    "    hyperparameters={\"alpha_sigma\":.15, \"alpha_p_sigma\":1., \"alpha_p_conc0\":0.6, \n",
    "                     \"alpha_p_conc1\":0.6, \"alpha_rate\":1., \"pi_conc0\":0.5, \"alpha_conc\":100,\n",
    "                     \"scale_factor_alpha\":10000, \"scale_factor_centroid\":1000, \"scale_tau\":0},\n",
    "    store_parameters = True, \n",
    "    seed_list=[92],\n",
    "    nonparametric=True,\n",
    "    store_fits=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def mix_weights(beta):\n",
    "    '''\n",
    "    Function used for the stick-breaking process.\n",
    "    '''\n",
    "    print(\"beta =\", beta)\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    print(\"beta1m_cumprod =\", beta1m_cumprod)\n",
    "    res1 = F.pad(beta, (0, 1), value=1)\n",
    "    res2 = F.pad(beta1m_cumprod, (1, 0), value=1)\n",
    "    res = res1 * res2\n",
    "    print(f\"res1 = {res1}, res2 = {res2}, res = {res}\\n\")\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 6\n",
    "with pyro.plate(\"beta_plate\", cluster-1):\n",
    "    pi_beta = pyro.sample(f\"beta\", pyro.distributions.Beta(1, 1.1755e-36))\n",
    "    # pi_beta = torch.tensor([1.1755e-36, 2.1648e-18, 1.1755e-36, 6.6389e-33, 1.1755e-36])\n",
    "    print(\"pi_beta =\", pi_beta)\n",
    "    pi = mix_weights(pi_beta)\n",
    "\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_star = torch.zeros(k_denovo, 96, dtype=torch.float64) \n",
    "for i in range(k_denovo):\n",
    "    tmp_sbs = torch.cat((ref_sbs, dn_sbs[i].unsqueeze(0)))\n",
    "    beta_star[i] = pi[i].unsqueeze(0).matmul(tmp_sbs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Gamma(0.01, 0.01).sample((5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.distributions.Dirichlet(torch.ones(5)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - pyro.distributions.Beta(1, 1e-10).sample((cluster-1,))).cumprod(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = torch.zeros((10,))\n",
    "pi[:5] = 5\n",
    "pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_centr = mixture[0].params[\"alpha_prior\"]\n",
    "print(alpha_centr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.normalized_mutual_info_score(mixture.groups, g_sbs)) \n",
    "print(sklearn.metrics.normalized_mutual_info_score(mixture.groups, g_dbs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_sbs.params[\"scale_factor_centroid\"])\n",
    "print(obj_sbs.params[\"scale_factor_alpha\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.train_params[6][\"scale_factor_centroid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sbs.params[\"pi_conc0\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(obj_sbs.likelihoods)), y=obj_sbs.likelihoods) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(obj_sbs.losses)), y=obj_sbs.losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"scale_factor_centroid_param\"])), \n",
    "                     y=obj_sbs.gradient_norms[\"scale_factor_centroid_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"scale_factor_alpha_param\"])), \n",
    "                     y=obj_sbs.gradient_norms[\"scale_factor_alpha_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha_prior_param\"])), y=obj_sbs.gradient_norms[\"alpha_prior_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha_prior_param\"])), y=obj_sbs.gradient_norms[\"alpha_prior_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"pi_param\"])), y=obj_sbs.gradient_norms[\"pi_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"pi_conc0_param\"])), y=obj_sbs.gradient_norms[\"pi_conc0_param\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"alpha\"])), y=obj_sbs.gradient_norms[\"alpha\"]) \n",
    "except: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: sns.scatterplot(x=range(len(obj_sbs.gradient_norms[\"beta_denovo\"])), y=obj_sbs.gradient_norms[\"beta_denovo\"])\n",
    "except: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(obj_sbs.init_params[\"alpha_prior_param\"]), columns=obj_sbs.params[\"alpha\"].columns).plot.bar(stacked=True, legend=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: pd.DataFrame(np.array(obj_sbs.params[\"alpha_prior\"]), columns=obj_sbs.params[\"alpha_prior\"].columns).plot.bar(stacked=True, legend=False) \n",
    "except Exception as e: print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for gid in set(np.array(obj_sbs.groups)):\n",
    "        tmp = [i for i, v in enumerate(obj_sbs.groups) if v == gid]\n",
    "        # tmp = [i for i, v in enumerate(obj_sbs.groups) if (v == gid and i in idxs)]\n",
    "        if len(tmp) == 0: continue\n",
    "        pd.DataFrame(np.array(obj_sbs.params[\"alpha\"]), columns=obj_sbs.params[\"alpha\"].columns, \n",
    "                     index=obj_sbs.params[\"alpha\"].index).iloc[tmp].plot.bar(stacked=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    obj_sbs.alpha.plot.bar(stacked=True, legend=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for sbs in pd.concat((obj_sbs.params[\"beta_f\"], obj_sbs.params[\"beta_d\"])).index:\n",
    "        pd.concat((obj_sbs.params[\"beta_f\"], obj_sbs.params[\"beta_d\"])).loc[[sbs]].transpose().plot.bar()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
